<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js rust">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>uniexam</title>
        <meta name="robots" content="noindex" />
        <!-- Custom HTML head -->
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "rust";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('rust')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="index.html">Introduction</a></li><li class="chapter-item expanded affix "><a href="syllabi.html">Syllabi</a></li><li class="chapter-item expanded "><a href="ai.html"><strong aria-hidden="true">1.</strong> Artificial Intelligence</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="u1.1.html"><strong aria-hidden="true">1.1.</strong>  Adversarial Search and Games </a></li><li class="chapter-item expanded "><a href="u1.2.html"><strong aria-hidden="true">1.2.</strong>  Knowledge </a></li><li class="chapter-item expanded "><a href="u1.3.html"><strong aria-hidden="true">1.3.</strong>  Reasoning </a></li><li class="chapter-item expanded "><a href="u1.4.html"><strong aria-hidden="true">1.4.</strong>  Planning </a></li><li class="chapter-item expanded "><a href="ai_prelim.html"><strong aria-hidden="true">1.5.</strong>  Questions </a></li></ol></li><li class="chapter-item expanded "><a href="cc.html"><strong aria-hidden="true">2.</strong> Cloud Computing</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="u2.1.html"><strong aria-hidden="true">2.1.</strong> Virtualization in Cloud Computing</a></li><li class="chapter-item expanded "><a href="u2.2.html"><strong aria-hidden="true">2.2.</strong> Cloud Platforms and Cloud Applications</a></li><li class="chapter-item expanded "><a href="u2.3.html"><strong aria-hidden="true">2.3.</strong> Security in Cloud Computing</a></li><li class="chapter-item expanded "><a href="u2.4.html"><strong aria-hidden="true">2.4.</strong> Advanced Techniques in Cloud Computing</a></li><li class="chapter-item expanded "><a href="cc_prelim.html"><strong aria-hidden="true">2.5.</strong>  Questions </a></li></ol></li><li class="chapter-item expanded "><a href="dsbda.html"><strong aria-hidden="true">3.</strong> Data Science and Big Data</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="u3.1.html"><strong aria-hidden="true">3.1.</strong> Big Data Analytics Life Cycle</a></li><li class="chapter-item expanded "><a href="u3.2.html"><strong aria-hidden="true">3.2.</strong> Predictive Big Data Analytics with Python</a></li><li class="chapter-item expanded "><a href="u3.3.html"><strong aria-hidden="true">3.3.</strong> Big Data Analytics and Model Evaluation</a></li><li class="chapter-item expanded "><a href="u3.4.html"><strong aria-hidden="true">3.4.</strong> Data Visualization and Hadoop</a></li><li class="chapter-item expanded "><a href="dsbda_prelim.html"><strong aria-hidden="true">3.5.</strong>  Questions </a></li></ol></li><li class="chapter-item expanded "><a href="wt.html"><strong aria-hidden="true">4.</strong> Web Technologies</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="u4.1.html"><strong aria-hidden="true">4.1.</strong> Java Servlets and XML</a></li><li class="chapter-item expanded "><a href="u4.2.html"><strong aria-hidden="true">4.2.</strong> JSP and Web Services</a></li><li class="chapter-item expanded "><a href="u4.3.html"><strong aria-hidden="true">4.3.</strong> Server Side Scripting Languages</a></li><li class="chapter-item expanded "><a href="u4.4.html"><strong aria-hidden="true">4.4.</strong> Ruby and Rails</a></li><li class="chapter-item expanded "><a href="wt_prelim.html"><strong aria-hidden="true">4.5.</strong>  Questions </a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">uniexam</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<p><strong>Notes for computer engg. sem 6 SPPU university exam</strong></p>
<p><em>You may notice <strong>NEEDS REFACTORING</strong> bullets which mean that the topic might
be incomplete.</em></p>
<h2 id="progress"><a class="header" href="#progress">PROGRESS</a></h2>
<ul>
<li><input disabled="" type="checkbox"/>
Artificial Intelligence
<ul>
<li><input disabled="" type="checkbox"/>
Unit III <strong>Adversarial Search and Games</strong></li>
<li><input disabled="" type="checkbox"/>
Unit IV <strong>Knowledge</strong></li>
<li><input disabled="" type="checkbox"/>
Unit V <strong>Reasoning</strong></li>
<li><input disabled="" type="checkbox"/>
Unit VI <strong>Planning</strong></li>
<li><input disabled="" type="checkbox"/>
Prelim Questions</li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Cloud Computing
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Unit III <strong>Virtualization in Cloud Computing</strong></li>
<li><input disabled="" type="checkbox" checked=""/>
Unit IV <strong>Cloud Platforms and Cloud Applications</strong></li>
<li><input disabled="" type="checkbox" checked=""/>
Unit V <strong>Security in Cloud Computing</strong></li>
<li><input disabled="" type="checkbox" checked=""/>
Unit VI <strong>Advanced Techniques in Cloud Computing</strong></li>
<li><input disabled="" type="checkbox" checked=""/>
Prelim Questions</li>
</ul>
</li>
<li><input disabled="" type="checkbox"/>
Data Science and Big Data
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Unit III <strong>Big Data Analytics Life Cycle</strong></li>
<li><input disabled="" type="checkbox"/>
Unit IV <strong>Predictive Big Data Analytics with Python</strong></li>
<li><input disabled="" type="checkbox" checked=""/>
Unit V <strong>Big Data Analytics and Model Evaluation</strong></li>
<li><input disabled="" type="checkbox" checked=""/>
Unit VI <strong>Data Visualization and Hadoop</strong></li>
<li><input disabled="" type="checkbox"/>
Prelim Questions</li>
</ul>
</li>
<li><input disabled="" type="checkbox"/>
Web technologies
<ul>
<li><input disabled="" type="checkbox"/>
Unit III <strong>Java Servlets and XML</strong></li>
<li><input disabled="" type="checkbox"/>
Unit IV <strong>JSP and Web Services</strong></li>
<li><input disabled="" type="checkbox"/>
Unit V <strong>Server Side Scripting Languages</strong></li>
<li><input disabled="" type="checkbox"/>
Unit VI <strong>Ruby and Rails</strong></li>
<li><input disabled="" type="checkbox"/>
Prelim Questions</li>
</ul>
</li>
</ul>
<h2 id="btw"><a class="header" href="#btw">BTW,</a></h2>
<ul>
<li>
<p>Entire theory was based on google searches</p>
</li>
<li>
<p>Tried to keep the notes short but failed in some areas.</p>
</li>
<li>
<p>Navigating through the notes is pretty easy:</p>
<ul>
<li>
<p>Sidebar can be toggled with the help of the hamburger menu in the top left
corner.</p>
</li>
<li>
<p>Use the paint brush button to change the theme.</p>
</li>
<li>
<p>Search button for fast fuzzy search through the entire book.</p>
</li>
</ul>
</li>
<li>
<p>To read more information about a topic, look for &quot;More Details&quot; whenever
necessary. They are a link to the topic's resource.</p>
</li>
<li>
<p>Improvements are welcome. Email me at: <a href="mailto:zim@onionmail.org">zim@onionmail.org</a></p>
</li>
<li>
<p>Source code for this book can be found at:
<a href="https://github.com/zim0369/uniexam">https://github.com/zim0369/uniexam</a>.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="syllabi"><a class="header" href="#syllabi">SYLLABI</a></h1>
<h2 id="artificial-intelligence"><a class="header" href="#artificial-intelligence">Artificial Intelligence</a></h2>
<ul>
<li>
<p>Unit III <strong>Adversarial Search and Games</strong></p>
<p>Game Theory, Optimal Decisions in Games, Heuristic Alpha–Beta Tree Search, Monte Carlo Tree
Search, Stochastic Games, Partially Observable Games, Limitations of Game Search Algorithms,
Constraint Satisfaction Problems (CSP), Constraint Propagation: Inference in CSPs, Backtracking
Search for CSPs.</p>
</li>
<li>
<p>Unit IV <strong>Knowledge</strong></p>
<p>Logical Agents, Knowledge-Based Agents, The Wumpus World, Logic, Propositional Logic: A
Very Simple Logic, Propositional Theorem Proving, Effective Propositional Model Checking,
Agents Based on Propositional Logic, First-Order Logic, Representation Revisited, Syntax and
Semantics of First-Order Logic, Using First-Order Logic, Knowledge Engineering in First-Order
Logic.</p>
</li>
<li>
<p>Unit V <strong>Reasoning</strong></p>
<p>Inference in First-Order Logic, Propositional vs. First-Order Inference, Unification and First-Order
Inference, Forward Chaining, Backward Chaining, Resolution, Knowledge Representation,
Ontological Engineering, Categories and Objects, Events, Mental Objects, and Modal Logic,
Reasoning Systems for Categories, Reasoning with Default Information</p>
</li>
<li>
<p>Unit VI <strong>Planning</strong></p>
<p>Automated Planning, Classical Planning, Algorithms for Classical Planning, Heuristics for
Planning, Hierarchical Planning, Planning and Acting in Nondeterministic Domains, Time,
Schedules, and Resources, Analysis of Planning Approaches, Limits of AI, Ethics of AI, Future of
AI, AI Components, AI Architectures.</p>
</li>
</ul>
<h2 id="cloud-computing"><a class="header" href="#cloud-computing">Cloud Computing</a></h2>
<ul>
<li>
<p>Unit III <strong>Virtualization in Cloud Computing</strong></p>
<p>Introduction: Definition of Virtualization, Adopting Virtualization, Types of Virtualization,
Virtualization Architecture and Software, Virtual Clustering, Virtualization Application, Pitfalls of
Virtualization. Grid, Cloud and Virtualization: Virtualization in Grid, Virtualization in Cloud,
Virtualization and Cloud Security. Virtualization and Cloud Computing: Anatomy of Cloud
Infrastructure, Virtual infrastructures, CPU Virtualization, Network and Storage Virtualization.</p>
</li>
<li>
<p>Unit IV <strong>Cloud Platforms and Cloud Applications</strong></p>
<p>Amazon Web Services (AWS): Amazon Web Services and Components, Amazon Simple DB,
Elastic Cloud Computing (EC2), Amazon Storage System, Amazon Database services (Dynamo
DB).Microsoft Cloud Services: Azure core concepts, SQL Azure, Windows Azure Platform
Appliance. Cloud Computing Applications: Healthcare: ECG Analysis in the Cloud, Biology:
Protein Structure Prediction, Geosciences: Satellite Image Processing, Business and Consumer
Applications: CRM and ERP, Social Networking, Google Cloud Application: Google App Engine.
Overview of OpenStack architecture.</p>
</li>
<li>
<p>Unit V <strong>Security in Cloud Computing</strong></p>
<p>Risks in Cloud Computing: Risk Management, Enterprise-Wide Risk Management, Types of
Risks in Cloud Computing. Data Security in Cloud: Security Issues, Challenges, advantages,
Disadvantages, Cloud Digital persona and Data security, Content Level Security. Cloud Security
Services: Confidentiality, Integrity and Availability, Security Authorization Challenges in the
Cloud, Secure Cloud Software Requirements, Secure Cloud Software Testing.</p>
</li>
<li>
<p>Unit VI <strong>Advanced Techniques in Cloud Computing</strong></p>
<p>Future Tends in cloud Computing, Mobile Cloud, Automatic Cloud Computing: Comet Cloud.
Multimedia Cloud: IPTV, Energy Aware Cloud Computing, Jungle Computing, Distributed Cloud
Computing Vs Edge Computing, Containers, Docker, and Kubernetes, Introduction to DevOps.
IOT and Cloud Convergence: The Cloud and IoT in your Home, The IOT and cloud in your
Automobile, PERSONAL: IoT in Healthcare.</p>
</li>
</ul>
<h2 id="data-science-and-big-data"><a class="header" href="#data-science-and-big-data">Data Science and Big Data</a></h2>
<ul>
<li>
<p>Unit III <strong>Big Data Analytics Life Cycle</strong></p>
<p>Introduction to Big Data, sources of Big Data, Data Analytic Lifecycle: Introduction, Phase 1:
Discovery, Phase 2: Data Preparation, Phase 3: Model Planning, Phase 4: Model Building, Phase 5:
Communication results, Phase 6: Operation alize.</p>
</li>
<li>
<p>Unit IV <strong>Predictive Big Data Analytics with Python</strong></p>
<p>Introduction, Essential Python Libraries, Basic examples. Data Preprocessing: Removing
Duplicates, Transformation of Data using function or mapping, replacing values, Handling Missing
Data. Analytics Types: Predictive, Descriptive and Prescriptive. Association Rules: Apriori
Algorithm, FP growth. Regression: Linear Regression, Logistic Regression. Classification: Naïve
Bayes, Decision Trees. Introduction to Scikit-learn, Installations, Dataset, mat plotlib, filling
missing values, Regression and Classification using Scikit-learn.</p>
</li>
<li>
<p>Unit V <strong>Big Data Analytics and Model Evaluation</strong></p>
<p>Clustering Algorithms: K-Means, Hierarchical Clustering, Time-series analysis. Introduction to
Text Analysis: Text-preprocessing, Bag of words, TF-IDF and topics. Need and Introduction to
social network analysis, Introduction to business analysis. Model Evaluation and Selection: Metrics
for Evaluating Classifier Performance, Holdout Method and Random Sub sampling, Parameter
Tuning and Optimization, Result Interpretation, Clustering and Time-series analysis using Scikit-
learn, sklearn. metrics, Confusion matrix, AUC-ROC Curves, Elbow plot.</p>
</li>
<li>
<p>Unit VI <strong>Data Visualization and Hadoop</strong></p>
<p>Introduction to Data Visualization, Challenges to Big data visualization, Types of data visualization,
Data Visualization Techniques, Visualizing Big Data, Tools used in Data Visualization, Hadoop
ecosystem, Map Reduce, Pig, Hive, Analytical techniques used in Big data visualization. Data
Visualization using Python: Line plot, Scatter plot, Histogram, Density plot, Box- plot.</p>
</li>
</ul>
<h2 id="web-technologies"><a class="header" href="#web-technologies">Web technologies</a></h2>
<ul>
<li>
<p>Unit III <strong>Java Servlets and XML</strong></p>
<p>Servlet: Servlet architecture overview, A “Hello World” servlet, Servlets generating dynamic
content, Servlet life cycle, parameter data, sessions, cookies, URL rewriting, other Servlet
capabilities, data storage, Servlets concurrency, databases (MySQL) and Java Servlets. XML:
XML documents and vocabularies, XML declaration, XML Namespaces, DOM based XML
processing, transforming XML documents, DTD: Schema, elements, attributes. AJAX:
Introduction, Working of AJAX.</p>
</li>
<li>
<p>Unit IV <strong>JSP and Web Services</strong></p>
<p>JSP: Introduction to Java Server Pages, JSP and Servlets, running JSP applications, Basic JSP,
JavaBeans classes and JSP, Support for the Model-View-Controller paradigm, JSP related
technologies. Web Services: Web Service concepts, Writing a Java Web Service, Writing a Java
web service client, Describing Web Services: WSDL, Communicating Object data: SOAP.
Struts: Overview, architecture, configuration, actions, interceptors, result types, validations,
localization, exception handling, annotations.</p>
</li>
<li>
<p>Unit V <strong>Server Side Scripting Languages</strong></p>
<p>PHP: Introduction to PHP, uses of PHP, general syntactic characteristics, Primitives, operations
and expressions, output, control statements, arrays, functions, pattern matching, form handling,
files, cookies, session tracking, using MySQL with PHP, WAP and WML. Introduction to
ASP.NET: Overview of the .NET Framework, Overview of C#, Introduction to ASP.NET,
ASP.NET Controls, Web Services. Overview of Node JS.</p>
</li>
<li>
<p>Unit VI <strong>Ruby and Rails</strong></p>
<p>Introduction to Ruby: Origins &amp; uses of Ruby, scalar types and their operations, simple input
and output, control statements, fundamentals of arrays, hashes, methods, classes, code blocks and
iterators, pattern matching. Introduction to Rails: Overview of Rails, Document Requests,
Processing Forms, Rails Applications and Databases, Layouts, Rails with Ajax. Introduction to
EJB.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="artificial-intelligence-1"><a class="header" href="#artificial-intelligence-1">Artificial Intelligence</a></h1>
<ul>
<li>
<p>Unit III <strong>Adversarial Search and Games</strong></p>
<p>Game Theory, Optimal Decisions in Games, Heuristic Alpha–Beta Tree Search, Monte Carlo Tree
Search, Stochastic Games, Partially Observable Games, Limitations of Game Search Algorithms,
Constraint Satisfaction Problems (CSP), Constraint Propagation: Inference in CSPs, Backtracking
Search for CSPs.</p>
</li>
<li>
<p>Unit IV <strong>Knowledge</strong></p>
<p>Logical Agents, Knowledge-Based Agents, The Wumpus World, Logic, Propositional Logic: A
Very Simple Logic, Propositional Theorem Proving, Effective Propositional Model Checking,
Agents Based on Propositional Logic, First-Order Logic, Representation Revisited, Syntax and
Semantics of First-Order Logic, Using First-Order Logic, Knowledge Engineering in First-Order
Logic.</p>
</li>
<li>
<p>Unit V <strong>Reasoning</strong></p>
<p>Inference in First-Order Logic, Propositional vs. First-Order Inference, Unification and First-Order
Inference, Forward Chaining, Backward Chaining, Resolution, Knowledge Representation,
Ontological Engineering, Categories and Objects, Events, Mental Objects, and Modal Logic,
Reasoning Systems for Categories, Reasoning with Default Information</p>
</li>
<li>
<p>Unit VI <strong>Planning</strong></p>
<p>Automated Planning, Classical Planning, Algorithms for Classical Planning, Heuristics for
Planning, Hierarchical Planning, Planning and Acting in Nondeterministic Domains, Time,
Schedules, and Resources, Analysis of Planning Approaches, Limits of AI, Ethics of AI, Future of
AI, AI Components, AI Architectures.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="adversarial-search-and-games"><a class="header" href="#adversarial-search-and-games">Adversarial Search and Games</a></h1>
<!-- ## Adversarial Search -->
<!-- **Adversarial search is a search, where we examine the problem which arises when -->
<!-- we try to plan ahead of the world and other agents are planning against us.** -->
<!-- The environment with more than one agent is termed as multi-agent environment, -->
<!-- in which each agent is an opponent of other agent and playing against each -->
<!-- other. Each agent needs to consider the action of other agent and effect of that -->
<!-- action on their performance. -->
<!-- Searches in which two or more players with conflicting goals are trying to -->
<!-- explore the same search space for the solution, are called adversarial searches, -->
<!-- often known as Games. -->
<!-- Games are modeled as a Search problem and heuristic evaluation function, and -->
<!-- these are the two main factors which help to model and solve games in AI. -->
<!-- ## Game Theory -->
<!-- **Game theory is the study of mathematical models of strategic interactions -->
<!-- among rational agents. It has applications in all fields of social science, as -->
<!-- well as in logic, systems science and computer science.** -->
<!-- *   Types of Games: -->
<!--     1.  Zero-Sum and Non-Zero Sum Games -->
<!--     2.  Simultaneous and Sequential Games -->
<!--     3.  Imperfect Information and Perfect Information Games -->
<!--     4.  Asymmetric and Symmetric Games -->
<!--     5.  Co-operative and Non-Co-operative Games -->
<!-- ## Optimal Decisions in Games -->
<!-- **Games are usually intriguing because they are difficult to solve. Chess, for -->
<!-- example, has an average branching factor of around 35, and games frequently -->
<!-- stretch to 50 moves per player, therefore the search tree has roughly 35100 or -->
<!-- 10154 nodes (despite the search graph having “only” about 1040 unique nodes). As -->
<!-- a result, games, like the real world, necessitate the ability to make some sort -->
<!-- of decision even when calculating the best option is impossible.** -->
<!-- *   The optimal strategy can be found from the minimax value of each node, which -->
<!--     we express as MINIMAX, given a game tree (n). Assuming that both players -->
<!--     play optimally from there through the finish of the game, the utility (for -->
<!--     MAX) of being in the corresponding state is the node's minimax value. -->
<!-- *   [Optimal Decision in Gaming -->
<!--     example](https://www.geeksforgeeks.org/optimal-decision-making-in-games/) -->
<!-- ## Heuristic Alpha–Beta Tree Search -->
<!-- **Alpha-beta pruning is a modified version of the minimax algorithm. It is an -->
<!-- optimization technique for the minimax algorithm.** -->
<!-- *   The two-parameter can be defined as: -->
<!--     *   **Alpha**: The best (highest-value) choice we have found so far at any -->
<!--         point along the path of Maximizer. The initial value of alpha is **-∞**. -->
<!--     *   **Beta**: The best (lowest-value) choice we have found so far at any -->
<!--         point along the path of Minimizer. The initial value of beta is **+∞**. -->
<!-- *   The Alpha-beta pruning to a standard minimax algorithm returns the same move -->
<!--     as the standard algorithm does, but it removes all the nodes which are not -->
<!--     really affecting the final decision but making algorithm slow. Hence by -->
<!--     pruning these nodes, it makes the algorithm fas -->
<!-- *   The main condition which required for alpha-beta pruning is: **α>=β** -->
<!-- *   [Pseudo-code & Working](https://www.javatpoint.com/ai-alpha-beta-pruning) -->
<!-- ## Monte Carlo Tree Search -->
<!-- **Monte Carlo tree search is a heuristic search algorithm for some kinds of -->
<!-- decision processes, most notably those employed in software that plays board -->
<!-- games. In that context MCTS is used to solve the game tree.** -->
<!-- *   MCTS can be broken down into 4 steps: -->
<!--     1.  **Selection**: In this process, the MCTS algorithm traverses the current -->
<!--         tree from the root node using a specific strategy. The strategy uses an -->
<!--         evaluation function to optimally select nodes with the highest estimated -->
<!--         value. -->
<!--         ![MCTS formula](pictures/mcts_formula.png) -->
<!--         where: -->
<!--         *   Si = value of a node i -->
<!--         *   xi = empirical mean of a node i -->
<!--         *   C = a constant -->
<!--         *   t = total number of simulations -->
<!--     2.  **Expansion**: In this process, a new child node is added to the tree to -->
<!--         that node which was optimally reached during the selection process. -->
<!--     3.  **Simulation**: In this process, a simulation is performed by choosing -->
<!--         moves or strategies until a result or predefined state is achieved. -->
<!--     4.  **Backpropagation**: After determining the value of the newly added -->
<!--         node, the remaining tree must be updated. During the process, the number of -->
<!--         simulation stored in each node is incremented. Also, if the new node’s -->
<!--         simulation results in a win, then the number of wins is also incremented. -->
<!-- *   [More -->
<!--     Details](https://www.geeksforgeeks.org/ml-monte-carlo-tree-search-mcts/) -->
<!-- ## Stochastic Game -->
<!-- *   **In game theory, a stochastic game, is a repeated game with probabilistic -->
<!--     transitions played by one or more players. The game is played in a sequence -->
<!--     of stages. At the beginning of each stage the game is in some state.** -->
<!-- *   [Example with backgammon -->
<!--     game](https://www.geeksforgeeks.org/stochastic-games-in-artificial-intelligence/) -->
<!-- ## Partially Observable Games, -->
<!-- *   **A partially observable system is one in which the entire state of the -->
<!--     system is not fully visible to an external sensor. In a partially observable -->
<!--     system the observer may utilise a memory system in order to add information -->
<!--     to the observer's understanding of the system.** -->
<!-- *   Example: A card game in which some of the cards are discarded into a pile face -->
<!--     down. In this case the observer is only able to view their own cards and -->
<!--     potentially those of the dealer. -->
<!-- ## Limitations of Game Search Algorithms, -->
<div style="break-before: page; page-break-before: always;"></div><h1 id="knowledge"><a class="header" href="#knowledge">Knowledge</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="adversarial-search-and-games-1"><a class="header" href="#adversarial-search-and-games-1">Adversarial Search and Games</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="knowledge-1"><a class="header" href="#knowledge-1">Knowledge</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="questions"><a class="header" href="#questions">Questions</a></h1>
<p><strong>These questions are the questions from SKN's recent(May 2022) prelim examinations</strong></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cloud-computing-1"><a class="header" href="#cloud-computing-1">Cloud Computing</a></h1>
<ul>
<li>
<p>Unit III <strong>Virtualization in Cloud Computing</strong></p>
<p>Introduction: Definition of Virtualization, Adopting Virtualization, Types of Virtualization,
Virtualization Architecture and Software, Virtual Clustering, Virtualization Application, Pitfalls of
Virtualization. Grid, Cloud and Virtualization: Virtualization in Grid, Virtualization in Cloud,
Virtualization and Cloud Security. Virtualization and Cloud Computing: Anatomy of Cloud
Infrastructure, Virtual infrastructures, CPU Virtualization, Network and Storage Virtualization.</p>
</li>
<li>
<p>Unit IV <strong>Cloud Platforms and Cloud Applications</strong></p>
<p>Amazon Web Services (AWS): Amazon Web Services and Components, Amazon Simple DB,
Elastic Cloud Computing (EC2), Amazon Storage System, Amazon Database services (Dynamo
DB).Microsoft Cloud Services: Azure core concepts, SQL Azure, Windows Azure Platform
Appliance. Cloud Computing Applications: Healthcare: ECG Analysis in the Cloud, Biology:
Protein Structure Prediction, Geosciences: Satellite Image Processing, Business and Consumer
Applications: CRM and ERP, Social Networking, Google Cloud Application: Google App Engine.
Overview of OpenStack architecture.</p>
</li>
<li>
<p>Unit V <strong>Security in Cloud Computing</strong></p>
<p>Risks in Cloud Computing: Risk Management, Enterprise-Wide Risk Management, Types of
Risks in Cloud Computing. Data Security in Cloud: Security Issues, Challenges, advantages,
Disadvantages, Cloud Digital persona and Data security, Content Level Security. Cloud Security
Services: Confidentiality, Integrity and Availability, Security Authorization Challenges in the
Cloud, Secure Cloud Software Requirements, Secure Cloud Software Testing.</p>
</li>
<li>
<p>Unit VI <strong>Advanced Techniques in Cloud Computing</strong></p>
<p>Future Tends in cloud Computing, Mobile Cloud, Automatic Cloud Computing: Comet Cloud.
Multimedia Cloud: IPTV, Energy Aware Cloud Computing, Jungle Computing, Distributed Cloud
Computing Vs Edge Computing, Containers, Docker, and Kubernetes, Introduction to DevOps.
IOT and Cloud Convergence: The Cloud and IoT in your Home, The IOT and cloud in your
Automobile, PERSONAL: IoT in Healthcare.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="unit-iii-virtualization-in-cloud-computing"><a class="header" href="#unit-iii-virtualization-in-cloud-computing">Unit III: Virtualization in Cloud Computing</a></h1>
<ul>
<li>Virtualization in cloud computing allows a provider to virtualize servers,
storage, or other physical hardware or data center resources, which can
then, in turn, allow them to provide numerous services such as
infrastructure, software, and platforms.</li>
</ul>
<h2 id="adopting-virtualization"><a class="header" href="#adopting-virtualization">Adopting Virtualization</a></h2>
<ul>
<li>
<p>Some users may confuse virtualization with cloud computing, but they’re not
entirely the same.</p>
<ul>
<li>
<p>Virtualization is the creation of a virtual resource such as a server,
desktop, operating system, file, storage space, or network to help
businesses manage and scale workloads.</p>
</li>
<li>
<p>Cloud computing is the sharing of resources, software, applications and
data as a service. Together, the two can be used to provide even greater
advantages.</p>
</li>
</ul>
</li>
<li>
<p>Reasons to adopt virtualization:</p>
<ol>
<li>Increased agility for the business</li>
<li>Better resource deployment</li>
<li>Greater operational efficiency</li>
<li>Enhanced security</li>
<li>Higher availability</li>
<li>Stronger disaster recovery</li>
<li>Improved quality of service</li>
<li>Reduced energy consumption</li>
<li>Preparation for the cloud</li>
</ol>
</li>
</ul>
<h2 id="types-of-virtualization"><a class="header" href="#types-of-virtualization">Types of Virtualization</a></h2>
<ul>
<li>
<p>Types of Virtualization</p>
<ol>
<li>Application Virtualization.</li>
<li>Network Virtualization.</li>
<li>Desktop Virtualization.</li>
<li>Storage Virtualization.</li>
<li>Server Virtualization.</li>
<li>Data virtualization.</li>
</ol>
</li>
<li>
<p><a href="https://www.geeksforgeeks.org/virtualization-cloud-computing-types/">More Details</a></p>
</li>
</ul>
<h2 id="virtualization-architecture--software"><a class="header" href="#virtualization-architecture--software">Virtualization architecture &amp; software</a></h2>
<h3 id="virtualization-architecture"><a class="header" href="#virtualization-architecture">Virtualization architecture</a></h3>
<ul>
<li>
<p>A virtualization architecture is a conceptual model specifying the
arrangement and interrelationships of the particular components involved in
delivering a virtual -- rather than physical -- version of something, such
as an operating system (OS), a server, a storage device or network
resources.</p>
<p><img src="pictures/traditional_vs_virtual.png" alt="Traditional vs Virtual" /></p>
<p><em>Left: Traditional architecture | Right: Virtual architecture</em></p>
<p><a href="https://www.techtarget.com/whatis/definition/virtualization-architecture">More
Details</a></p>
</li>
</ul>
<h3 id="virtualization-software"><a class="header" href="#virtualization-software">Virtualization software</a></h3>
<ul>
<li>
<p>Virtualization software, also called hypervisor, allows a single host
computer to create and run one or more virtual environments.</p>
</li>
<li>
<p>Virtualization software is most often used to emulate a complete computer
system in order to allow a guest operating system to be run, for example
allowing Linux to run as a guest on top of a PC that is natively running a
Microsoft Windows operating system (or the inverse, running Windows as a
guest on Linux).</p>
</li>
<li>
<p>Uses of virtualization software:</p>
<ol>
<li><strong>Back up</strong>: You can backup your entire operating system or server
installation as a virtual OS.</li>
<li><strong>Run a different OS</strong>: Let's say you want to try out Linux without
having to install it on a physical hard drive.</li>
<li><strong>Run ancient apps</strong>: Say an application you want to run only works on
win8 and you're using win10 then instead of reinstalling an outdated OS on
real hardware why not just install windows 8 in a VM.</li>
<li><strong>Look at dirty files</strong>: Taking a look at malicious files might put your
computer and your data at risk so it would be better to check it in a
sandboxed environment.</li>
<li><strong>Using sandboxed browsers</strong>: Hackers have successfully exploited all
four of most popular browsers — Chrome, Internet Explorer, Firefox, and
Safari. Browser plugins can be malicious too. In this case using a sandboxed
browser like the TOR browser is safer.</li>
<li><strong>Try an application</strong>: You just want to check if an application you
wrote works well on multiple operating systems then using virtual machines
would be more convenient as compared to installing on real hardware.</li>
</ol>
</li>
</ul>
<h2 id="virtual-clustering"><a class="header" href="#virtual-clustering">Virtual Clustering</a></h2>
<ul>
<li>
<p>Virtual clusters are built with VMs installed at distributed servers from one or more physical clus-ters. The VMs in a virtual cluster are interconnected logically by a virtual network across several physical networks. Figure 3.18 illustrates the concepts of virtual clusters and physical clusters. Each virtual cluster is formed with physical machines or a VM hosted by multiple physical clusters. The virtual cluster boundaries are shown as distinct boundaries.</p>
</li>
<li>
<p>The provisioning of VMs to a virtual cluster is done dynamically to have the following interest-ing properties:</p>
<ul>
<li>The virtual cluster nodes can be either physical or virtual machines. Multiple VMs running with different OSes can be deployed on the same physical node.</li>
<li>A VM runs with a guest OS, which is often different from the host OS, that manages the resources in the physical machine, where the VM is implemented.</li>
<li>The purpose of using VMs is to consolidate multiple functionalities on the same server. This will greatly enhance server utilization and application flexibility.</li>
</ul>
</li>
<li>
<p><a href="https://www.brainkart.com/article/Virtual-Clusters-and-Resource-Management_11343/">More Details</a></p>
</li>
</ul>
<h2 id="virtual-applications"><a class="header" href="#virtual-applications">Virtual Applications</a></h2>
<ul>
<li>
<p>Virtual apps are applications that are optimized to run in a virtual
environment. Simply put, a virtual app simply runs on a computer without
being installed on it.</p>
</li>
<li>
<p>Remote apps are a popular virtual app delivery solution wherein the virtual
applications installed on a server are delivered to users’ devices. These
applications are not installed on the user’s device; instead, software
called a client is installed on the device that connects to the server, and
the application is presented as screenshots sent to the device.</p>
</li>
<li>
<p>ThinApp is an example of an agentless application virtualization solution,
while Microsoft App-V represents an agent-based virtual app solution.
Parallels Remote Application Server, Citrix, and VMware are the leading
providers of application virtualization solutions in the market.</p>
</li>
</ul>
<h2 id="pitfalls-of-virtualization"><a class="header" href="#pitfalls-of-virtualization">Pitfalls of Virtualization</a></h2>
<p><em>Have added both pros and cons</em></p>
<ul>
<li>
<p>Pros</p>
<ol>
<li>Cheaper</li>
<li>Predictable costs</li>
<li>reduced workload</li>
<li>Better uptime</li>
<li>Faster deployment of resources</li>
<li>Promotes digital entrepreneurship</li>
<li>Energy savings</li>
</ol>
</li>
<li>
<p>Cons(pitfalls)</p>
<ol>
<li>High implementation cost</li>
<li>Has limitations</li>
<li>Security risk</li>
<li>Availability issue</li>
<li>Scalability issue</li>
<li>Requires several links in a chain that must work together cohesively</li>
<li>Time consuming</li>
</ol>
</li>
</ul>
<h2 id="grid-cloud--virtualization"><a class="header" href="#grid-cloud--virtualization">Grid, Cloud &amp; Virtualization</a></h2>
<h3 id="grid-computing"><a class="header" href="#grid-computing">Grid Computing</a></h3>
<ul>
<li>
<p>Grid Computing can be defined as a network of computers working together to
perform a task that would rather be difficult for a single machine. All
machines on that network work under the same protocol to act as a virtual
supercomputer.</p>
</li>
<li>
<p>The task that they work on may include analyzing huge datasets or simulating
situations that require high computing power.</p>
</li>
<li>
<p>Computers on the network contribute resources like processing power and
storage capacity to the network.</p>
</li>
<li>
<p>Grid computing is also called as &quot;distributed computing.&quot; It links multiple
computing resources (PC's, workstations, servers, and storage elements)
together and provides a mechanism to access them.</p>
</li>
<li>
<p>The main advantages of grid computing are that it increases user
productivity by providing transparent access to resources, and work can be
completed more quickly.</p>
</li>
</ul>
<h3 id="cloud"><a class="header" href="#cloud">Cloud</a></h3>
<ul>
<li>
<p>&quot;The cloud&quot; refers to servers that are accessed over the Internet, and the
software and databases that run on those servers. Cloud servers are located
in data centers all over the world. By using cloud computing, users and
companies do not have to manage physical servers themselves or run software
applications on their own machines.</p>
</li>
<li>
<p>The cloud enables users to access the same files and applications from
almost any device, because the computing and storage takes place on servers
in a data center, instead of locally on the user device. This is why a user
can log in to their Instagram account on a new phone after their old phone
breaks and still find their old account in place, with all their photos,
videos, and conversation history. It works the same way with cloud email
providers like Gmail or Microsoft Office 365, and with cloud storage
providers like Dropbox or Google Drive.</p>
</li>
</ul>
<h3 id="virtualization"><a class="header" href="#virtualization">Virtualization</a></h3>
<ul>
<li>
<p>Virtualization in cloud computing is defined as a creation of a virtual
version of a server, a desktop, a storage device, an operating system, or
network resources.</p>
</li>
<li>
<p>Virtualization in cloud computing allows a provider to virtualize servers,
storage, or other physical hardware or data center resources, which can
then, in turn, allow them to provide numerous services such as
infrastructure, software, and platforms.</p>
</li>
<li>
<p>Virtualization is a technique, which allows to share a single physical
instance of a resource or an application among multiple customers and
organizations. It does by assigning a logical name to a physical storage and
providing a pointer to that physical resource when demanded.</p>
</li>
<li>
<p>Types of Virtualization:</p>
<p><a href="u2.1.html#types-of-virtualization">Refer Types of Virtualization section above</a></p>
</li>
</ul>
<h3 id="virtualization-in-grid"><a class="header" href="#virtualization-in-grid">Virtualization in Grid</a></h3>
<ul>
<li>
<p>Whereas a grid has many systems in a network and hence multiple people can have ownership. Virtualization helps in providing cloud better security. Grid computing is more economical. It splits the work and distributes it over the network on computers increasing the efficiency as well.</p>
</li>
<li>
<p>Virtualization allows addressing multiple problems in Grid systems, such as
coping with the heterogeneity of Grid resources, the difference in software
stacks, and enhanced features in resource management such as more general
check pointing or migration models. Adopting virtualization in smart ways
gets us closer to real Grid computing with more ﬂexibility in the type of
applications and the resources to use.</p>
</li>
<li>
<p>Grid computing enables the virtualization of distributed computing resources suchas processing, network bandwidth,and storage capacity to create a single system image, granting users and applications seamless access to vast IT capabilities.</p>
</li>
</ul>
<h3 id="virtualization-in-cloud"><a class="header" href="#virtualization-in-cloud">Virtualization in Cloud</a></h3>
<ul>
<li>
<p>Virtualization plays a very important role in the cloud computing
technology, normally in the cloud computing, users share the data present in
the clouds like application etc, but actually with the help of
virtualization users shares the Infrastructure.</p>
</li>
<li>
<p>The main usage of Virtualization Technology is to provide the applications
with the standard versions to their cloud users, suppose if the next version
of that application is released, then cloud provider has to provide the
latest version to their cloud users and practically it is possible because
it is more expensive.</p>
</li>
<li>
<p>To overcome this problem we use basically virtualization technology, By
using virtualization, all severs and the software application which are
required by other cloud providers are maintained by the third party people,
and the cloud providers has to pay the money on monthly or annual basis.</p>
</li>
<li>
<p>Types of Virtualization in Cloud Computing:</p>
<ol>
<li>Application Virtualization</li>
<li>Network Virtualization</li>
<li>Desktop Virtualization</li>
<li>Storage Virtualization</li>
<li>Server Virtualization</li>
<li>Data virtualization</li>
</ol>
</li>
</ul>
<h3 id="virtualization-and-cloud-security"><a class="header" href="#virtualization-and-cloud-security">Virtualization and Cloud Security.</a></h3>
<ul>
<li>
<p>Cloud security, also known as cloud computing security, is a collection of
security measures designed to protect cloud-based infrastructure,
applications, and data. These measures ensure user and device
authentication, data and resource access control, and data privacy
protection. They also support regulatory data compliance. Cloud security is
employed in cloud environments to protect a company's data from distributed
denial of service (DDoS) attacks, malware, hackers, and unauthorized user
access or use.</p>
</li>
<li>
<p>Types of clouds:</p>
<ol>
<li>
<p><strong>Public clouds:</strong> Public cloud services are hosted by third-party cloud
service providers. A company doesn't have to set up anything to use the
cloud, since the provider handles it all. Usually, clients can access a
provider's web services via web browsers. Security features, such as access
control, identity management, and authentication, are crucial to public
clouds.</p>
</li>
<li>
<p><strong>Private clouds:</strong> Private clouds are typically more secure than public
clouds, as they're usually dedicated to a single group or user and rely on
that group or user's firewall. The isolated nature of these clouds helps
them stay secure from outside attacks since they're only accessible by one
organization. However, they still face security challenges from some
threats, such as social engineering and breaches. These clouds can also be
difficult to scale as your company's needs expand.</p>
</li>
<li>
<p><strong>Hybrid clouds:</strong> Hybrid clouds combine the scalability of public
clouds with the greater control over resources that private clouds offer.
These clouds connect multiple environments, such as a private cloud and a
public cloud, that can scale more easily based on demand. Successful hybrid
clouds allow users to access all their environments in a single integrated
content management platform.</p>
</li>
</ol>
</li>
<li>
<p>Cloud security is critical since most organizations are already using cloud
computing in one form or another. This high rate of adoption of public cloud
services is reflected in Gartner’s recent prediction that the worldwide
market for public cloud services will grow 23.1% in 2021.</p>
</li>
<li>
<p>Virtualized security, or security virtualization, refers to security
solutions that are software-based and designed to work within a virtualized
IT environment. This differs from traditional, hardware-based network
security, which is static and runs on devices such as traditional firewalls,
routers, and switches.</p>
</li>
</ul>
<h2 id="virtualization-and-cloud-computing"><a class="header" href="#virtualization-and-cloud-computing">Virtualization and Cloud Computing</a></h2>
<h3 id="anatomy-of-cloud-infrastructure"><a class="header" href="#anatomy-of-cloud-infrastructure">Anatomy of Cloud Infrastructure</a></h3>
<ul>
<li>
<p>Anatomy of Cloud Computing</p>
<ul>
<li>
<p><strong>Provisioning and Configuration Module:</strong> It is the lowest level of
cloud and typically resides on bare hardware (as a firmware) or on the
top of the hypervisor layer. Its function is to abstract the underlying
hardware and provide a standard mechanism to spawn instance of virtual
machine on demand. It also handles the post-configuration of the
operating systems and applications residing on the VM</p>
</li>
<li>
<p><strong>Monitoring and Optimization:</strong> This layer handles the monitoring of
all services, storage, networking and applications components in cloud.
Based on the statistics, it could perform routine functions that
optimize the behavior of the infrastructure components and provide
relevant data to the cloud administrator to further optimize the
configuration for maximum utilization and performance,</p>
</li>
<li>
<p><strong>Metering and Chargeback:</strong> This layer provides functions to measure
the usage of resources in cloud. The metering module collects all the
utilization data per domain per use. This module gives the cloud
administrator enough data to measure ongoing utilization of resources
and to create invoices based on the usage on a periodic basis.</p>
</li>
<li>
<p><strong>Orchestration:</strong> Orchestration is a central to cloud operations.
Orchestration converts requests from the service management layer and
the monitoring, chargeback modules to appropriate action item which are
then submitted to provisioning and configuration module for final
closure. Orchestration updates the CMDB in the process.</p>
</li>
<li>
<p><strong>Configuration Management Database (CMDB):</strong> It is a central
configuration repository wherein all the meta data and configuration of
different modules, resources are kept and updated in the real-time
basis. The repository can then be accessed using standards protocols
like SOAP by third-party software and integration components. All
updates in CMDB happen in real time as requests get processed in cloud.</p>
</li>
<li>
<p><strong>Cloud Life cycle Management Layer (CLM):</strong> This layer handles the
coordination of all other layers in cloud. All requests internal and
external are addressed to the CLM layer first. CLM may internally route
requests and actions to other layers for further processing.</p>
</li>
<li>
<p><strong>Service Catalog:</strong> It is central to the definition of cloud, SC
defines what kind of services the cloud is capable of providing and at
what cost to the end user. SC is the first thing that is drafted before
a cloud is architecture. The service management layer consults SC before
it processes any request for a new resource.</p>
</li>
</ul>
</li>
</ul>
<h3 id="virtual-infrastructures"><a class="header" href="#virtual-infrastructures">Virtual infrastructures</a></h3>
<ul>
<li>
<p>A virtual infrastructure allows you to utilise the IT capabilities of
physical resources as software that can be used across multiple platforms.
These resources are shared across multiple virtual machines (VMs) and
applications for maximum efficiency, creating a virtual infrastructure.</p>
</li>
<li>
<p>Benefits of virtual infrastructure</p>
<ul>
<li><strong>Cost savings:</strong> By consolidating servers, virtualization reduces
capital and operating costs associated with variables such as electrical
power, physical security, hosting and server development.</li>
<li><strong>Scalability:</strong> A virtual infrastructure allows organizations to react
quickly to changing customer demands and market trends by ramping up on
CPU utilization or scaling back accordingly.</li>
<li><strong>Increased productivity:</strong> Faster provisioning of applications and
resources allows IT teams to respond more quickly to employee demands
for new tools and technologies.</li>
<li><strong>Simplified server management:</strong> Simplified server management makes
sure IT teams can spin up, or down, virtual machines when required and
re-provision resources based on real-time needs.</li>
</ul>
</li>
<li>
<p><a href="https://www.vmware.com/topics/glossary/content/virtual-infrastructure.html">More
Details</a></p>
</li>
</ul>
<h3 id="cpu-virtualization"><a class="header" href="#cpu-virtualization">CPU Virtualization</a></h3>
<ul>
<li>
<p>CPU Virtualization is a hardware feature found in all current AMD &amp; Intel
CPUs that allows a single processor to act as if it was multiple individual
CPUs.This allows an operating system to more effectively &amp; efficiently
utilize the CPU power in the computer so that it runs faster.</p>
</li>
<li>
<p>CPU Virtualization emphasizes performance, running apps/programs, and runs
directly on the processor whenever possible. All operations are controlled
by an emulator that controls software to run accordingly, CPU Virtualisation
is not the same as emulation. The emulator works the same as a normal
computer machine does, it makes a copy of data and generates the same output
as a physical machine does. The emulation function gives a feeling of
working on multiple platforms while being on a single platform.</p>
</li>
<li>
<p>CPU Virtualization helps all the virtual machines to behave like physical
machines and distribute their physical resources like virtual machines
sharing their physical memories.</p>
</li>
<li>
<p>CPU Virtualization improves performance and efficiency to a greater extent
because virtual machines work on a single CPU, sharing resources is actually
like using multiple processors at the same time. This saves Cost and Money.</p>
</li>
<li>
<p>Types of CPU Virtualization:</p>
<ol>
<li>
<p><strong>Hardware-assisted CPU Virtualization :</strong> Hardware supports CPU
Virtualization through certain processors like Guest User. This Uses
different versions of code and the mode is known as a Guest mode. The best
part of hardware-assisted CPU Virtualization is, it doesn’t need any
translation while we use it for Hardware assistance. In short, it uplifts
system calls and makes them run faster than expected.</p>
</li>
<li>
<p><strong>Software-based CPU Virtualization :</strong> This type of CPU Virtualization
is software-based and it helps application code to get executed on a
processor. First, the privileged code gets translated, and then translated
code is directly executed on the processor. This translation process is
known as Binary Translation. The translated code is slow in execution and is
very large at the same time. Guest programs that are programmed in
privileged coding run very smoothly and fast. Applications with privileged
coding would run slower comparatively in a virtual environment.</p>
</li>
<li>
<p><strong>Virtualization and Processor-Specific behavior:</strong> Although this
software virtualizes the CPU, the virtual machine can detect the model of a
processor on which it is running, processor models may differ in CPU
features they offer and applications running on these CPUs may use these
features. Therefore it is not possible to use v motion to transfer virtual
machines running on processors with different feature sets.</p>
</li>
</ol>
</li>
</ul>
<h3 id="network-and-storage-virtualization"><a class="header" href="#network-and-storage-virtualization">Network and Storage Virtualization.</a></h3>
<h4 id="network-virtualization"><a class="header" href="#network-virtualization">Network Virtualization</a></h4>
<p>Network virtualization is a method of combining the available resources in a
network to consolidate multiple physical networks, divide a network into
segments or create software networks between virtual machines (VMs).</p>
<p><a href="u2.1.html#virtualization">Refer virtualization section for more</a></p>
<h4 id="storage-virtualization"><a class="header" href="#storage-virtualization">Storage Virtualization</a></h4>
<p>Storage virtualization in Cloud Computing is nothing but the sharing of physical
storage into multiple storage devices which further appears to be a single
storage device. It can be also called as a group of an available storage device
which simply manages from a central console.</p>
<p><a href="u2.1.html#virtualization">Refer virtualization section for more</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="unit-iv-cloud-platforms-and-cloud-applications"><a class="header" href="#unit-iv-cloud-platforms-and-cloud-applications">Unit IV: Cloud Platforms and Cloud Applications</a></h1>
<h2 id="amazon-web-services-aws-amazon-web-services-and-components"><a class="header" href="#amazon-web-services-aws-amazon-web-services-and-components">Amazon Web Services (AWS): Amazon Web Services and Components</a></h2>
<ul>
<li>Amazon Web Services, Inc. is a subsidiary of Amazon that provides on-demand
cloud computing platforms and APIs to individuals, companies, and
governments, on a metered pay-as-you-go basis. These cloud computing web
services provide distributed computing processing capacity and software
tools via AWS server farms.</li>
</ul>
<h3 id="aws-services"><a class="header" href="#aws-services">AWS Services</a></h3>
<p><img src="pictures/aws_services.png" alt="AWS Services" /></p>
<ul>
<li>Amazon Web Services offer the following services for various computing
purposes:
<ol>
<li>Hosting a web site</li>
<li>Social networking</li>
<li>Academic computing</li>
<li>Sharing media</li>
<li>Hosting applications</li>
<li>Backup, storage, and disaster recovery</li>
<li>Media distribution and content delivery</li>
<li>Developing and testing environments</li>
<li>Search engines</li>
</ol>
</li>
</ul>
<h3 id="aws-components"><a class="header" href="#aws-components">AWS Components</a></h3>
<ol>
<li>
<p><strong>Data Management and Data Transfer:</strong> To run HPC applications in the AWS
cloud, you need to move the required data into the cloud. There are several data
transport solutions designed to securely transfer huge amounts of data. This
overcomes issues like a long time for transfer, high network costs, and security
concerns. Also, you can automate the movement of data between the AWS cloud and
on-premises storage. There are options for establishing a private connection to
the AWS from your premises. This increases bandwidth to provide more throughput,
reduces the cost of the network, and provides a consistent network experience.</p>
</li>
<li>
<p><strong>Compute &amp; Networking:</strong> There are several compute instances types that can
be customized according to your needs. It also handles monitoring your
application and adjusting its capacity for maintaining a steady and predictable
performance at an affordable cost. Also, setting up application scaling across
multiple services for multiple resources takes a few minutes. Enhanced
networking options from AWS allow achieving lower inter-instance latency and
higher bandwidth.</p>
</li>
<li>
<p><strong>Storage:</strong> When looking for an HPC solution, you need to consider the
storage options and cost. There are several flexible blocks, object, and file
storage options in AWS services that allow permanent and transient data storage.
It allows allocating storage volumes according to the size you need. You can
store and access and data type over the cloud without doing a data migration
project. Also, with AWS services, you can transfer your workload to the cloud
from on-premises.</p>
</li>
<li>
<p><strong>Automation and Orchestration:</strong> For using the infrastructure efficiently,
you need to automate scheduling submitted jobs and the job submission process.
AWS services allow you to run thousands of batch computing jobs through the
dynamic provision of the computer resources on the basis of the requirements.</p>
</li>
<li>
<p><strong>Operations and Management:</strong> As a system administrator, you are
responsible for avoiding cost overruns and monitoring the infrastructure. There
are several management and monitoring services that allow you to optimize
utilization of resources, monitor the application, get a complete view of
operational health, and respond to the performance changes.</p>
</li>
<li>
<p><strong>Visualization:</strong> With the AWS services, you can easily visualize the
engineering simulations’ results without moving huge amounts of data. Now, you
can access the interactive applications remotely over a standard network and
deliver application sessions to any workstation.</p>
</li>
<li>
<p><strong>Security and Compliance:</strong> For running applications on the cloud, you need
to have an understanding of regulatory compliance and security management. There
are several quick-launch templates and security related services offered by AWS
that helps in protecting data and customer privacy by putting strong safeguards
in the AWS infrastructure.</p>
</li>
</ol>
<h3 id="amazon-simple-db"><a class="header" href="#amazon-simple-db">Amazon Simple DB</a></h3>
<ul>
<li>
<p>Amazon SimpleDB is a distributed database written in Erlang by Amazon.com.
It is used as a web service in concert with Amazon Elastic Compute Cloud and
Amazon S3 and is part of Amazon Web Services.</p>
</li>
<li>
<p><a href="https://aws.amazon.com/simpledb/">More Details</a></p>
</li>
</ul>
<h3 id="elastic-cloud-computing-ec2"><a class="header" href="#elastic-cloud-computing-ec2">Elastic Cloud Computing (EC2)</a></h3>
<ul>
<li>
<p><strong>Amazon Elastic Compute Cloud</strong> is a part of Amazon.com's cloud-computing
platform, Amazon Web Services, that allows users to rent virtual computers
on which to run their own computer applications.</p>
</li>
<li>
<p>EC2 refers to an on-demand computing service on the AWS cloud platform.
Under computing, it includes all the services a computing device can offer
to you along with the flexibility of a virtual environment. It also allows
the user to configure their instances as per their requirements i.e.
allocate the RAM, ROM, and storage according to the need of the current
task. Even the user can dismantle the virtual device once its task is
completed and it is no more required. For providing, all these scalable
resources AWS charges some bill amount at the end of every month, bill
amount is entirely dependent on your usage.</p>
</li>
<li>
<p>Features of Amazon EC2:</p>
<ul>
<li><strong>Functionality:</strong> EC2 provides its users a true virtual computing
platform, where they can various operations and even launch another EC2
instance from this virtually created environment. This will increase the
security of these virtual devices. Not only creating but also EC2 allows
us to customize our environment as per our requirements, at any point of
time during the life span of this virtual machine. Amazon EC2 itself
comes with a set of default AMI(Amazon Machine Image) options supporting
various operating systems along with some pre-configured resources like
RAM, ROM, storage, etc. Besides these AMI options, we can also create an
AMI curated with the combination of default and user-defined
configurations. And for future purposes, we can store this user-defined
AMI, so that next time, the user won’t have to re-configure a new AMI
from scratch. Rather than this whole process, the user can simply use
the older reference while creating a new EC2 machine.</li>
<li><strong>Operating Systems:</strong> Amazon EC2 includes a wide range of operating
systems to choose from while selecting your AMI. Not only these selected
options, but users are also even given the privileges to upload their
own operating systems and opt for that while selecting AMI during
launching an EC2 instance. Currently, AWS has the following most
preferred set of operating systems available on the EC2 console.
<ul>
<li>Amazon Linux</li>
<li>Windows Server</li>
<li>Ubuntu Server</li>
<li>SUSE Linux</li>
<li>Red Hat Linux</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Software:</strong> Amazon is single-handedly ruling the cloud computing market,
because of the variety of options available on it for its users. It allows
its users to choose from various software present to run on their EC2
machines. This whole service is allocated to AWS Marketplace on the AWS
platform. Numerous software like SAP, LAMP and Drupal, etc are available on
AWS to use.</p>
</li>
<li>
<p><strong>Scalability and Reliability:</strong> EC2 provides us the facility to scale up or
scale down as per the needs. All dynamic scenarios can easily be tackled by
EC2 with the help of this feature. And because of the flexibility of volumes
and snapshots, it is highly reliable for its users. Due to the scalable
nature of the machine, many organizations like Flipkart, Amazon rely on days
whenever humongous traffic occurs on their portals.</p>
</li>
</ul>
<h3 id="amazon-storage-system"><a class="header" href="#amazon-storage-system">Amazon Storage System</a></h3>
<ul>
<li>
<p>Amazon Simple Storage Service (Amazon S3) is an object storage service that
offers industry-leading scalability, data availability, security, and
performance.</p>
</li>
<li>
<p><a href="https://aws.amazon.com/products/storage/">More Details</a></p>
</li>
</ul>
<h3 id="amazon-database-services-dynamo-db"><a class="header" href="#amazon-database-services-dynamo-db">Amazon Database services (Dynamo DB).</a></h3>
<ul>
<li>
<p>Amazon DynamoDB is a fully managed proprietary NoSQL database service that
supports key–value and document data structures and is offered by Amazon.com
as part of the Amazon Web Services portfolio. DynamoDB exposes a similar
data model to and derives its name from Dynamo, but has a different
underlying implementation.</p>
</li>
<li>
<p><a href="https://aws.amazon.com/dynamodb/">More Details</a></p>
</li>
</ul>
<h2 id="microsoft-cloud-services"><a class="header" href="#microsoft-cloud-services">Microsoft Cloud Services</a></h2>
<ul>
<li>Microsoft Azure, often referred to as Azure, is a cloud computing service
operated by Microsoft for application management via Microsoft-managed data
centers.</li>
</ul>
<h3 id="azure-core-concepts"><a class="header" href="#azure-core-concepts">Azure core concepts</a></h3>
<!-- TABLE -->
<table><thead><tr><th>Concept Name</th><th>Description</th></tr></thead><tbody>
<tr><td><strong>Regions</strong></td><td>Azure is a global cloud platform which is available across various regions around the world. When you request a service, application, or VM in Azure, you are first asked to specify a region. The selected region represents datacenter where your application runs.</td></tr>
<tr><td><strong>Datacenter</strong></td><td>In Azure, you can deploy your applications into a variety of data centers around the globe. So, it is advisable to select a region which is closer to most of your customers. It helps you to reduce latency in network requests.</td></tr>
<tr><td><strong>Azure portal</strong></td><td>The Azure portal is a web-based application which can be used to create, manage and remove Azure resource and services. It is located at https://portal.azure.com.</td></tr>
<tr><td><strong>Resources</strong></td><td>Azure resource is an individual computer, networking data or app hosting services which charged individually. Some common resources are virtual machines( VM), storage account, or SQL databases.</td></tr>
<tr><td><strong>Resource groups</strong></td><td>An Azure resource group is a container which holds related resource for an Azure solution. It may include every resource or just resource which you wants to manage.</td></tr>
<tr><td><strong>Resource Manager templates</strong></td><td>It is a JSON which defines one or more resource to deploy to a resource group. It also establishes dependencies between deployed resources.</td></tr>
<tr><td><strong>Automation:</strong></td><td>Azure allows you to automate the process of creating, managing and deleting resource by using PowerShell or the Azure command-line Interface(CLI).</td></tr>
<tr><td><strong>Azure PowerShell</strong></td><td>PowerShell is a set of modules that offer cmdlets to manage Azure. In most cases, you are allowed to use, the cmdlets command for the same tasks which you are performing in the Azure portal.</td></tr>
<tr><td><strong>Azure command-line interface(CLI)</strong></td><td>The Azure CLI is a tool that you can use to create, manage, and remove Azure resources from the command line.</td></tr>
<tr><td><strong>REST APIs</strong></td><td>Azure is built on a set of REST APIs help you perform the same operation that you do in Azure portal Ul. It allows your Azure resources and apps to be manipulated via any third party software application.</td></tr>
</tbody></table>
<h3 id="sql-azure"><a class="header" href="#sql-azure">SQL Azure</a></h3>
<ul>
<li>
<p>Microsoft Azure SQL Database is a managed cloud database provided as part of
Microsoft Azure. A cloud database is a database that runs on a cloud
computing platform, and access to it is provided as a service. Managed
database services take care of scalability, backup, and high availability of
the database.</p>
</li>
<li>
<p><a href="https://docs.microsoft.com/en-us/azure/azure-sql/database/sql-database-paas-overview?view=azuresql">More
Details</a></p>
</li>
</ul>
<h3 id="windows-azure-platform-appliance"><a class="header" href="#windows-azure-platform-appliance">Windows Azure Platform Appliance.</a></h3>
<ul>
<li>
<p>The Windows Azure Platform Appliance consists of Windows Azure, SQL Azure
and a Microsoft-specified configuration of network, storage and server
hardware. Service providers, governments and large enterprises who would,
for example, invest in a 1000 servers at a time, will be able to deploy the
Windows Azure platform on their own hardware in their datacenter.
Microsoft Windows Azure Platform Appliance is optimized for scale out
applications - such as eBay- and datacenter efficiency across hundreds to
thousands to tens-of-thousands servers.</p>
</li>
<li>
<p><a href="https://azure.microsoft.com/en-in/blog/just-announced-at-wpc-the-windows-azure-platform-appliance/">More
Details</a></p>
</li>
</ul>
<h2 id="cloud-computing-applications"><a class="header" href="#cloud-computing-applications">Cloud Computing Applications:</a></h2>
<ul>
<li>
<p>Cloud service providers provide various applications in the field of art,
business, data storage and backup services, education, entertainment,
management, social networking, etc.</p>
</li>
<li>
<p><a href="https://www.javatpoint.com/cloud-computing-applications">More Details</a></p>
</li>
</ul>
<h3 id="healthcare"><a class="header" href="#healthcare">Healthcare</a></h3>
<ul>
<li>Cloud computing in healthcare describes the practice of implementing remote
servers accessed via the internet to store, manage and process
healthcare-related data. This is in contrast to establishing an on-site data
center with servers, or hosting the data on a personal computer.</li>
</ul>
<ol>
<li>
<p><strong>Collaboration:</strong> Sharing facilitates collaboration. As healthcare
information is meant to stay confidential, with the cloud, the data can be
securely shared among all the relevant healthcare stakeholders like doctors,
nurses, and care-givers that, too, in real-time.</p>
</li>
<li>
<p><strong>Security:</strong> Healthcare data needs to stay confidential. The abundant data
held by this domain makes it a focal point of attraction to the malicious
actors, resulting in security and data breaches.</p>
</li>
<li>
<p><strong>Cost:</strong> Cloud can hold an enormous amount of information at a very minimal
cost. Cloud computing works on the pay-as-you-go and subscription model,
which indicates you only have to pay for those services which you are
availing.</p>
</li>
<li>
<p><strong>Speed:</strong> Cloud-based tools can update and upgrade their features at a
commendable pace with minimal intervention, and you can get real-time updates
as well on all the relevant information.</p>
</li>
<li>
<p><strong>Scalability and Flexibility:</strong> Cloud facilitates technologies that are used
in healthcare like electronic medical records, mobile apps, patient portals,
devices with IoT, big data analytics.</p>
</li>
</ol>
<h4 id="ecgelectrocardiogram-analysis-in-the-cloud"><a class="header" href="#ecgelectrocardiogram-analysis-in-the-cloud">ECG(Electrocardiogram) Analysis in the Cloud</a></h4>
<ul>
<li>
<p><strong>ECG analysis in cloud computing</strong>: cloud computing technologies allows the
remote monitoring of a patient's heart beat data. Through this way the
patient at risk can be constantly monitored without going to the hospital
for ECG analysis. At the same time the Doctor's can instantly be notified
with cases that need's their attention.</p>
</li>
<li>
<p>An ECG is just a visual image of a record of the electrical activity of the
heart muscle as it varies over time, typically printed on paper for easier
study. Similarly, like other muscles, the heart contracts in response to
electrical depolarization caused in the muscle cells. When it's the time of
day, it's the amount of the electrical activity, when amplified and registered
for just a few seconds that we call a heart rhythm.</p>
</li>
<li>
<p>With ECG data collection and tracking, it's possible to test for chest pain,
low-grade heart rhythm disturbances, arrhythmias, and more. An E-G
(electrocardiogram) is the electrical expression of the contractile movement
of the myocardium.</p>
</li>
<li>
<p>Advantages:</p>
<ul>
<li>
<p>Since cloud computing systems are now readily available and deliver the
services in less time, it's got the promise to be a massive disruptor to
how the technology is distributed.</p>
</li>
<li>
<p>As a consequence, the doctor doesn't need to put a huge effort into
computing, since there is a lot of software on which to run.</p>
</li>
<li>
<p>Cloud infrastructure is highly scalable; it can be maximized and
minimized according to the needs of each user.</p>
</li>
<li>
<p>Cloud computing (or cloud computing) systems are now available and aim
to provide reliable services to consumers with less time.</p>
</li>
<li>
<p>The doctor's office would not need to invest in a broad computer system.</p>
</li>
</ul>
</li>
</ul>
<h3 id="biology"><a class="header" href="#biology">Biology</a></h3>
<ul>
<li>Cloud computing is an emerging technology that provides various computing
services on demand. It provides convenient access to a shared pool of
higher-level services and other system resources. Nowadays, cloud computing
has a great significance in the fields of geology, biology, and other
scientific research areas.</li>
</ul>
<h4 id="protein-structure-prediction"><a class="header" href="#protein-structure-prediction">Protein Structure Prediction</a></h4>
<ul>
<li>
<p>Protein structure prediction is the best example in research area that makes
use of cloud applications for its computation and storage.</p>
</li>
<li>
<p>A protein is composed of long chains of amino acids joined together by
peptide bonds. The various structures of protein help in the designing of
new drugs and the various sequences of proteins from its three-dimensional
structure in predictive form is known as a Protein structure prediction.</p>
</li>
<li>
<p>Firstly primary structures of proteins are formed and then prediction of the
secondary, tertiary and quaternary structures are done from the primary one.
In this way predictions of protein structures are done. Protein structure
prediction also makes use of various other technologies like artificial
neural networks, artificial intelligence, machine learning and probabilistic
techniques, also holds great importance in fields like theoretical chemistry
and bioinformatics.</p>
</li>
<li>
<p>There are various algorithms and tools that exists for protein structure
prediction. CASP (Critical Assessment of Protein Structure Prediction) is a
well-known tool that provides methods for automated web servers and the
results of research work are placed on clouds like CAMEO (Continuous
Automated Model Evaluation) server. These servers can be accessed by anyone
as per their requirements from any place. Some of the tools or servers used
in protein structure prediction are Phobius, FoldX, LOMETS, Prime, Predict
protein, SignalP, BBSP, EVfold, Biskit, HHpred, Phre, ESyired3D. Using these
tools new structures are predicted and the results are placed on the
cloud-based servers.</p>
</li>
</ul>
<h3 id="geosciences"><a class="header" href="#geosciences">Geosciences</a></h3>
<ul>
<li>Earth science or geoscience includes all fields of natural science related
to the planet Earth.</li>
</ul>
<h4 id="satellite-image-processing"><a class="header" href="#satellite-image-processing">Satellite Image Processing,</a></h4>
<ul>
<li>
<p>Satellite Image Processing is an important field in research and development
and consists of the images of earth and satellites taken by the means of
artificial satellites. Firstly, the photographs are taken in digital form
and later are processed by the computers to extract the information.
Statistical methods are applied to the digital images and after processing
the various discrete surfaces are identified by analyzing the pixel values.</p>
</li>
<li>
<p>Majorly there are four kinds of resolutions associated with satellite
imagery. These are:</p>
<ul>
<li><strong>Spatial resolution:</strong> It is determined by the sensors Instantaneous
Field of View(IFoV) and is defined as the pixel size of an image that is
visible to the human eye being measured on the ground. Since it has high
resolving power or the ability to separate and hence is termed as
Spatial Resolution.</li>
<li><strong>Spectral resolution:</strong> This resolution measures the wavelength
internal size and determines the number of wavelength intervals that the
sensor measures.</li>
<li><strong>Temporal resolution:</strong> The word temporal is associated with time or
days and is defined as the time that passes between various imagery
cloud periods.</li>
<li><strong>Radiometric resolution:</strong> This resolution provides the actual
characteristics of the image and is generally expressed in bits size. It
gives the effective bit depth and records the various levels of
brightness of imaging system.</li>
</ul>
</li>
</ul>
<h3 id="business-and-consumer-applications"><a class="header" href="#business-and-consumer-applications">Business and Consumer Applications</a></h3>
<h4 id="crm-and-erp"><a class="header" href="#crm-and-erp">CRM and ERP</a></h4>
<ul>
<li>
<p>CRM (Customer Relationship Management) and ERP (Enterprise Resource
Planning) software are powerful tools for a business or enterprise to use.
CRM handles the sales, marketing, and customer service information.</p>
</li>
<li>
<p><a href="https://www.netsuite.com/portal/resource/articles/erp/erp-vs-crm.shtml">More
Details</a></p>
</li>
</ul>
<h4 id="social-networking"><a class="header" href="#social-networking">Social Networking</a></h4>
<ul>
<li>
<p>Social networks help boost internet usability by storing heavy multimedia
content in cloud storage systems. Videos and photographs are the most
popular content on social media, which essentially use up the maximum space
allocated to them. They have the capacity to slow down applications and
servers with all of their resource demands. Cloud computing vendors such as
Salesforce and Amazon nowadays provide varied services including Customer
Relationship Management (CRM) and Enterprise Resource Planning (ERP). As
they deliver these things through cloud servers, clients can use the
flexibility and scalability of the system without purchasing standalone
software or hardware.</p>
</li>
<li>
<p>Apart from data storage, the social networks are now also using clouds for
various other tasks. For example, this can be ideal for big data analytics.
One of the benefits of using cloud systems is that users can access vast
amount of structured and even non-structured data easily. Just take a look
at the much-improved analytics provided by sites like Facebook, especially
for its business users.</p>
</li>
<li>
<p>Another way cloud computing becomes helpful is by reducing the cost of data
backup and recovery in case of a disaster. If the data is only stored in one
central location, it becomes much riskier. If something happens there, it is
almost impossible to recover the data. But through cloud they remain
accessible through shared resources across the globe. This is especially
useful for social networks as the store personal data of its users, and so
cannot afford to lose even one part of it.</p>
</li>
</ul>
<h3 id="google-cloud-application"><a class="header" href="#google-cloud-application">Google Cloud Application</a></h3>
<ul>
<li>Google Cloud Platform, offered by Google, is a suite of cloud computing
services that runs on the same infrastructure that Google uses internally
for its end-user products, such as Google Search, Gmail, Google Drive, and
YouTube.</li>
</ul>
<h4 id="google-app-engine"><a class="header" href="#google-app-engine">Google App Engine.</a></h4>
<ul>
<li>
<p>Google App Engine is a cloud computing platform as a service for developing
and hosting web applications in Google-managed data centers. Applications
are sandboxed and run across multiple servers.</p>
</li>
<li>
<p><a href="https://www.techtarget.com/searchaws/definition/Google-App-Engine">More
Details</a></p>
</li>
</ul>
<h2 id="overview-of-openstack-architecture"><a class="header" href="#overview-of-openstack-architecture">Overview of OpenStack architecture.</a></h2>
<ul>
<li>
<p>OpenStack is a free, open standard cloud computing platform. It is mostly
deployed as infrastructure-as-a-service in both public and private clouds
where virtual servers and other resources are made available to users.</p>
</li>
<li>
<p>OpenStack contains a modular architecture along with several code names for
the components.</p>
</li>
</ul>
<p><img src="pictures/openstack.png" alt="openstack architecture" /></p>
<ul>
<li><a href="https://www.javatpoint.com/openstack-architecture">More Details</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="unit-v-security-in-cloud-computing"><a class="header" href="#unit-v-security-in-cloud-computing">Unit V: Security in Cloud Computing</a></h1>
<h2 id="risks-in-cloud-computing"><a class="header" href="#risks-in-cloud-computing">Risks in Cloud Computing</a></h2>
<h3 id="risk-management"><a class="header" href="#risk-management">Risk Management</a></h3>
<ul>
<li>
<p>Risk management is one of the cloud computing environment controls which
aims to assess and manage risks related to cloud computing and to prevent
those risks from impacting.</p>
</li>
<li>
<p>The risk-based approach of managing information systems is a holistic
activity that needs to be fully integrated into every aspect of the
organization, from planning to system development life cycle processes, to
security controls allocation and continuous monitoring. Therefore, a Risk
Management Framework (RMF) provides a disciplined and structured process
that integrates information security and risk management activities into the
system development life cycle. An RMF operates primarily at tier 3 in the
risk management hierarchy, but it can also have interactions at tier 1 and
tier 2.</p>
</li>
<li>
<p><a href="https://www.analyticssteps.com/blogs/8-pillars-risk-management-cloud-computing">More Details</a></p>
</li>
</ul>
<h3 id="enterprise-wide-risk-management"><a class="header" href="#enterprise-wide-risk-management">Enterprise-Wide Risk Management</a></h3>
<ul>
<li>
<p>Enterprise-wide risk management (ERM) is a process of coordinated risk
management that places greater emphasis on co-operation among departments to
manage an organisation's range of risks as a whole. ERM offers a framework
to effectively manage uncertainty, respond to risk and exploit opportunities
as they arise.</p>
</li>
<li>
<p>Five steps to ERM are:</p>
<ol>
<li>Identify Risk</li>
<li>Analyze Risk</li>
<li>Evaluate or Rank Risk</li>
<li>Treat Risk or Control Risk</li>
<li>Monitor and Review Risk</li>
</ol>
</li>
<li>
<p><a href="https://kmrdpartners.com/2018/04/05/enterprise-risk-management-process/">More
Details</a></p>
</li>
</ul>
<h3 id="types-of-risks-in-cloud-computing"><a class="header" href="#types-of-risks-in-cloud-computing">Types of Risks in Cloud Computing</a></h3>
<ol>
<li>
<p><strong>Data Loss:</strong> Data loss is the most common cloud security risks of cloud
computing. It is also known as data leakage. Data loss is the process in which
data is being deleted, corrupted, and unreadable by a user, software, or
application. In a cloud computing environment, data loss occurs when our
sensitive data is somebody else's hands, one or more data elements can not be
utilized by the data owner, hard disk is not working properly, and software is
not updated.</p>
</li>
<li>
<p><strong>Hacked Interfaces and Insecure APIs:</strong> As we all know, cloud computing is
completely depends on Internet, so it is compulsory to protect interfaces and
APIs that are used by external users. APIs are the easiest way to communicate
with most of the cloud services. In cloud computing, few services are available
in the public domain. These services can be accessed by third parties, so there
may be a chance that these services easily harmed and hacked by hackers.</p>
</li>
<li>
<p><strong>Data Breach:</strong> Data Breach is the process in which the confidential data
is viewed, accessed, or stolen by the third party without any authorization, so
organization's data is hacked by the hackers.</p>
</li>
<li>
<p><strong>Vendor lock-in:</strong> Vendor lock-in is the of the biggest security risks in
cloud computing. Organizations may face problems when transferring their
services from one vendor to another. As different vendors provide different
platforms, that can cause difficulty moving one cloud to another.</p>
</li>
<li>
<p><strong>Increased complexity strains IT staff:</strong> Migrating, integrating, and
operating the cloud services is complex for the IT staff. IT staff must require
the extra capability and skills to manage, integrate, and maintain the data to
the cloud.</p>
</li>
<li>
<p><strong>Spectre &amp; Meltdown:</strong> Spectre &amp; Meltdown allows programs to view and steal
data which is currently processed on computer. It can run on personal computers,
mobile devices, and in the cloud. It can store the password, your personal
information such as images, emails, and business documents in the memory of
other running programs.</p>
</li>
<li>
<p><strong>Denial of Service (DoS) attacks:</strong> Denial of service (DoS) attacks occur
when the system receives too much traffic to buffer the server. Mostly, DoS
attackers target web servers of large organizations such as banking sectors,
media companies, and government organizations. To recover the lost data, DoS
attackers charge a great deal of time and money to handle the data.</p>
</li>
<li>
<p><strong>Account hijacking:</strong> Account hijacking is a serious security risk in cloud
computing. It is the process in which individual user's or organization's cloud
account (bank account, e-mail account, and social media account) is stolen by
hackers. The hackers use the stolen account to perform unauthorized activities.</p>
</li>
</ol>
<h2 id="data-security-in-cloud"><a class="header" href="#data-security-in-cloud">Data Security in Cloud</a></h2>
<ul>
<li>
<p>The three letters in &quot;CIA triad&quot; stand for Confidentiality, Integrity, and
Availability. The CIA triad is a common model that forms the basis for the
development of security systems. They are used for finding vulnerabilities
and methods for creating solutions.</p>
</li>
<li>
<p>The core principles of information security and data governance—data
confidentiality, integrity, and availability (known as the CIA triad)—also
apply to the cloud:</p>
<ul>
<li><strong>Confidentiality:</strong> protecting the data from unauthorized access and
disclosure</li>
<li><strong>Integrity:</strong> safeguard the data from unauthorized modification so it
can be trusted</li>
<li><strong>Availability:</strong> ensuring the data is fully available and accessible
when it’s needed</li>
</ul>
</li>
</ul>
<p><strong>MORE DETAILED</strong></p>
<ul>
<li>
<p><strong>Confidentiality:</strong> Confidentiality involves the efforts of an organization
to make sure data is kept secret or private. To accomplish this, access to
information must be controlled to prevent the unauthorized sharing of
data—whether intentional or accidental. A key component of maintaining
confidentiality is making sure that people without proper authorization are
prevented from accessing assets important to your business. Conversely, an
effective system also ensures that those who need to have access have the
necessary privileges.</p>
<p>For example, those who work with an organization’s finances should be able
to access the spreadsheets, bank accounts, and other information related to
the flow of money. However, the vast majority of other employees—and perhaps
even certain executives—may not be granted access. To ensure these policies
are followed, stringent restrictions have to be in place to limit who can
see what.</p>
</li>
<li>
<p><strong>Integrity:</strong> Integrity involves making sure your data is trustworthy and
free from tampering. The integrity of your data is maintained only if the
data is authentic, accurate, and reliable.</p>
<p>For example, if your company provides information about senior managers on
your website, this information needs to have integrity. If it is inaccurate,
those visiting the website for information may feel your organization is not
trustworthy. Someone with a vested interest in damaging the reputation of
your organization may try to hack your website and alter the descriptions,
photographs, or titles of the executives to hurt their reputation or that of
the company as a whole.</p>
</li>
<li>
<p><strong>Availability:</strong> Even if data is kept confidential and its integrity
maintained, it is often useless unless it is available to those in the
organization and the customers they serve. This means that systems,
networks, and applications must be functioning as they should and when they
should. Also, individuals with access to specific information must be able
to consume it when they need to, and getting to the data should not take an
inordinate amount of time.</p>
<p>If, for example, there is a power outage and there is no disaster recovery
system in place to help users regain access to critical systems,
availability will be compromised. Also, a natural disaster like a flood or
even a severe snowstorm may prevent users from getting to the office, which
can interrupt the availability of their workstations and other devices that
provide business-critical information or applications. Availability can also
be compromised through deliberate acts of sabotage, such as the use of
denial-of-service (DoS) attacks or ransomware.</p>
</li>
</ul>
<h3 id="security-issues"><a class="header" href="#security-issues">Security Issues</a></h3>
<ol>
<li>
<p><strong>Data Loss:</strong> Data Loss is one of the issues faced in Cloud Computing. This
is also known as Data Leakage. As we know that our sensitive data is in the
hands of Somebody else, and we don’t have full control over our database. So if
the security of cloud service is to break by hackers then it may be possible
that hackers will get access to our sensitive data or personal files.</p>
</li>
<li>
<p><strong>Interference of Hackers and Insecure API’s:</strong> As we know if we are talking
about the cloud and its services it means we are talking about the Internet.
Also, we know that the easiest way to communicate with Cloud is using API. So it
is important to protect the Interface’s and API’s which are used by an external
user. But also in cloud computing, few services are available in the public
domain. An is the vulnerable part of Cloud Computing because it may be possible
that these services are accessed by some third parties. So it may be possible
that with the help of these services hackers can easily hack or harm our data.</p>
</li>
<li>
<p><strong>User Account Hijacking:</strong> Account Hijacking is the most serious security
issue in Cloud Computing. If somehow the Account of User or an Organization is
hijacked by Hacker. Then the hacker has full authority to perform Unauthorized
Activities.</p>
</li>
<li>
<p><strong>Changing Service Provider:</strong> Vendor lock In is also an important Security
issue in Cloud Computing. Many organizations will face different problems while
shifting from one vendor to another. For example, An Organization wants to shift
from AWS Cloud to Google Cloud Services then they ace various problem’s like
shifting of all data, also both cloud services have different techniques and
functions, so they also face problems regarding that. Also, it may be possible
that the charges of AWS are different from Google Cloud, etc.</p>
</li>
<li>
<p><strong>Lack of Skill:</strong> While working, shifting o another service provider, need
an extra feature, how to use a feature, etc. are the main problems caused in IT
Company who doesn’t have skilled Employee. So it requires a skilled person to
work with cloud Computing.</p>
</li>
<li>
<p><strong>Denial of Service (DoS) attack:</strong> This type of attack occurs when the
system receives too much traffic. Mostly DoS attacks occur in large
organizations such as the banking sector, government sector, etc. When a DoS
attack occurs data is lost. So in order to recover data, it requires a great
amount of money as well as time to handle it.</p>
</li>
</ol>
<h3 id="challenges"><a class="header" href="#challenges">Challenges</a></h3>
<ol>
<li>
<p><strong>DDoS and Denial-of-Service Attacks:</strong> As more and more businesses and
operations move to the cloud, cloud providers are becoming a bigger target for
malicious attacks. Distributed denial of service (DDoS) attacks are more common
than ever before. Verisign reported IT services, cloud platforms (PaaS) and SaaS
was the most frequently targeted industry during the first quarter of 2015.</p>
</li>
<li>
<p><strong>Data breaches:</strong> Known data breaches in the U.S. hit a record-high of 738
in 2014, according to the Identity Theft Research Center, and hacking was (by
far) the number one cause. That’s an incredible statistic and only emphasizes
the growing challenge to secure sensitive data.</p>
</li>
<li>
<p><strong>Data loss:</strong> When business critical information is moved into the cloud,
it’s understandable to be concerned with its security. Losing cloud data, either
through accidental deletion and human error, malicious tampering including the
installation of malware (i.e. DDoS), or an act of nature that brings down a
cloud service provider, could be disastrous for an enterprise business. Often a
DDoS attack is only a diversion for a greater threat, such as an attempt to
steal or delete data.</p>
</li>
<li>
<p><strong>Insecure access control points:</strong> One of the great benefits of the cloud
is it can be accessed from anywhere and from any device. But, what if the
interfaces and particularly the application programming interfaces (APIs) users
interact with aren’t secure? Hackers can find and gain access to these types of
vulnerabilities and exploit authentication via APIs if given enough time.</p>
</li>
<li>
<p><strong>Notifications and alerts:</strong> Awareness and proper communication of security
threats is a cornerstone of network security and the same goes for cloud
computing security. Alerting the appropriate website or application managers as
soon as a threat is identified should be part of a thorough data security and
access management plan. Speedy mitigation of a threat relies on clear and prompt
communication so steps can be taken by the proper entities and impact of the
threat minimized.</p>
</li>
</ol>
<h3 id="advantages"><a class="header" href="#advantages">Advantages</a></h3>
<ol>
<li>
<p><strong>24×7 Visibility:</strong> The best cloud security solutions like AppTrana enable
24×7 monitoring of the application and cloud-based assets. This helps
organizations to have continuous visibility into their risk posture and its
impact on the business.</p>
</li>
<li>
<p><strong>Higher Availability:</strong> Cloud computing security solutions typically have
built-in redundancies to ensure that the application/ resources are always
available. The CDNs used have distributed global networks of edge servers that
deliver content optimally, accelerate application performance, and minimize
access to the server. Together, they handle traffic surges in a way that
on-premises/ hardware solutions cannot.</p>
</li>
<li>
<p><strong>Effective protection against DDoS Attacks:</strong> Cloud security solutions
provide the most effective protection against DDoS attacks, which are increasing
in numbers, magnitude, sophistication, and severity. Cloud computing security
helps to continuously monitor, identify, analyze, and mitigate DDoS attacks. The
built-in redundancies, customizability, flexibility, scalability, and
intelligence of such solutions can prevent volumetric, low, and slow attacks.</p>
</li>
<li>
<p><strong>Data Security:</strong> The best cloud computing security solutions provide data
security by design. They have security protocols and policies such as strong
access controls and data encryption to prevent unauthorized entities from
accessing confidential information.</p>
</li>
<li>
<p><strong>Pay as you Go Model:</strong> The cloud security model ensures that you pay only
for what you use and consume as opposed to making any upfront investment.</p>
</li>
<li>
<p><strong>Advanced Threat Detection:</strong> By using end-point scanning and global threat
intelligence, cloud computing security can detect threats more easily.</p>
</li>
<li>
<p><strong>Regulatory Compliance:</strong> Top-notch cloud application security providers
help to ensure regulatory standards and industry-specific compliance needs. This
is done through its enhanced infrastructure and managed security services.</p>
</li>
</ol>
<h3 id="disadvantages"><a class="header" href="#disadvantages">Disadvantages</a></h3>
<ol>
<li>
<p><strong>Risk of data confidentiality:</strong> There is always a risk that user data can
be accessed by other people. So data and cloud protection must be good because
if it won’t be dangerous for data confidentiality.</p>
</li>
<li>
<p><strong>Depends on internet connection:</strong> The internet is the only way to cloud
computing. When there is no internet connection in your place, or the internet
path to the cloud provider is in trouble, automatically access to your cloud
computing machine will be disconnected. Now this is where the biggest obstacle
is happening in developing countries and remote areas that do not have good
internet access.And the weakness of public cloud is where everyone accesses the
same server and server and will increase the risk of attack, and down the
server.</p>
</li>
<li>
<p><strong>The level of security:</strong> Secrecy and security are among the most doubtful
things in cloud computing. By using a cloud computing system means we are fully
entrusted with the security and confidentiality of data to companies that
provide cloud computing servers. When you experience a problem, you cannot sue
the server for errors in the data. When you experience a problem, you cannot sue
the server for errors in the data.</p>
</li>
<li>
<p><strong>Compliance:</strong> Which refers to the risk of a level compliance deviation
from the provider against the regulations applied by the user.</p>
</li>
<li>
<p><strong>Vulnerable in the event of an attack:</strong> There are lots of arguments
against cloud computing one of which is computing because the Cloud Computing
work system is online, each component that is on Cloud Computing can be exposed
to a wide range, this is a wide open opportunity for attacks on data or
activities stored on the server. When an attack is carried out by hackers, the
problems that occur are data security, and data privacy.</p>
</li>
<li>
<p><strong>Data Mobility:</strong> which refers to the possibility of sharing data between
cloud services and how to retrieve data if one day the user makes a process of
terminating cloud computing services.And there is local storage where the data
can be used at any time as needed.</p>
</li>
<li>
<p><strong>Technical problem:</strong> Besides that the use of Cloud Computing makes you
unable to manage it yourself when there is a problem or a problem, you must
contact customer support who is not necessarily ready 24/7. This is a problem
because for some support you also have to pay more money.</p>
</li>
<li>
<p><strong>Low Connection:</strong> Does not work well if the connection is slow. The
quality of cloud computing servers is one of the most important considerations
before we decide to provide cloud computing server service providers. When the
server is down or the permorma is not good, we will be harmed because of poor
server quality.</p>
</li>
</ol>
<h3 id="cloud-digital-persona-and-data-security"><a class="header" href="#cloud-digital-persona-and-data-security">Cloud Digital persona and Data security</a></h3>
<ul>
<li>
<p><strong>Digital Persona</strong>: The digital representation of someone's personal information that is purposely created by the user or collected without the user's knowledge. For security purposes, people might create a digital persona with a Google Voice phone number that forwards to their private number. However, almost everyone who uses the Internet has a digital persona that is created by third parties and derived from their Web surfing history and social media posts.</p>
</li>
<li>
<p><a href="https://dokumen.pub/cloud-computing-a-practical-approach-for-learning-and-implementation-1e-9788131776513-9789332537255-8131776514.html">For more details find digital persona section on this web page</a></p>
</li>
<li>
<p><strong>Data Security</strong>: <a href="u2.3.html#data-security-in-cloud">Refer Data Security section above</a></p>
</li>
</ul>
<h3 id="content-level-security"><a class="header" href="#content-level-security">Content Level Security</a></h3>
<ul>
<li>Content Level Security (CLS) is a feature that controls who has access to
edit or read content. During the process of creating a document, the content
goes through several stages. Each stage requires input from users with
different roles.</li>
</ul>
<h2 id="cloud-security-services"><a class="header" href="#cloud-security-services">Cloud Security Services</a></h2>
<ol>
<li>
<p><strong>Identity and access:</strong> You are provided with control for secured
management of identities and access. It includes people, processes and systems
used for managing access to your enterprise resources. It is managed by making
sure that the identity of the user is verified and the access rights are
provided at the correct level.</p>
</li>
<li>
<p><strong>Data loss prevention:</strong> This service offers protection of data by
providing you with pre-installed data loss prevention software, along with a set
of rules deployed.</p>
</li>
<li>
<p><strong>Web security:</strong> Web security is provided as an additional protection
against malware from entering the enterprise through web browsing and other such
activities. This cloud service is provided either by installing a software or an
appliance or through the cloud by redirecting your web traffic over to the cloud
provider.</p>
</li>
<li>
<p><strong>E-mail security:</strong> It provides control over the in-bound and out-bound
e-mails to protect your organization from malicious attachments and phishing.
This cloud service helps enforce corporate policies such as acceptable use, spam
and in providing business continuity options. One of the solution adopted by
many cloud e-mail security services is digital signatures, which allows
identification and non-repudiation.</p>
</li>
<li>
<p><strong>Security assessment:</strong> There are various tools implemented for the users
of the SaaS delivery model, such as variant elasticity, low administration
overhead, negligible setup time and pay-per use with low investment in the
initial stage.</p>
</li>
<li>
<p><strong>Intrusion management:</strong> It is the process that uses pattern recognition
for detection and reaction to events that are statistically unusual and
unexpected. It may also require reconfiguration of your system components in
real time so as to prevent an intrusion.</p>
</li>
<li>
<p><strong>Security information and managing events:</strong> Your system gathers
information related to log and events. This information is used in correlating
and analyzing, to provide you with real time reporting and alerts on events that
require intervention.</p>
</li>
<li>
<p><strong>Encryption:</strong> There are typical algorithms that are computationally
difficult or nearly impossible to break.</p>
</li>
<li>
<p><strong>Disaster management:</strong> This cloud service helps in continuing your
business and managing disasters by providing flexibility and reliable failover
for services that are required in case of service interruptions.</p>
</li>
<li>
<p><strong>Network security:</strong> The network security services provides you with
address security controls, which in a cloud environment is generally provided
through virtual devices.</p>
</li>
</ol>
<h3 id="confidentiality"><a class="header" href="#confidentiality">Confidentiality</a></h3>
<ul>
<li>
<p>Data confidentiality is the process of protecting data from illegal access
and disclosure from the outsourced server and unauthorized users. This is
done by encrypting the data so that only the authorized users can decrypt
it.</p>
</li>
<li>
<p><a href="https://www.ibm.com/cloud/learn/confidential-computing">More Details</a></p>
</li>
</ul>
<h3 id="integrity-and-availability"><a class="header" href="#integrity-and-availability">Integrity and Availability</a></h3>
<ul>
<li>
<p><strong>Integrity:</strong> Protect the data from the unauthorized insert, update, or
delete. The data owner and authorized users should be able to recognize if
the data is corrupted or incomplete, and receive the most recent updated
version of the data, which guarantees accuracy and consistency of data.</p>
</li>
<li>
<p><strong>Availability:</strong> The data in the cloud servers should be accessible to its
users. Major threats to availability are denial of service (DOS) attacks,
natural disasters, and equipment failures at the service provider’s end.</p>
</li>
</ul>
<h3 id="security-authorization-challenges-in-the-cloud"><a class="header" href="#security-authorization-challenges-in-the-cloud">Security Authorization Challenges in the Cloud</a></h3>
<ol>
<li>
<p><strong>Data Breaches:</strong> Consequences of a data breach may include: Data breaches
put classified data at risk.</p>
</li>
<li>
<p><strong>Misconfiguration and Inadequate Change Control:</strong> This is one of the most
common challenges of the cloud. In 2017, a misconfigured AWS Simple Storage
Service (S3) cloud storage bucket exposed detailed and private data of 123
million American households.</p>
</li>
<li>
<p><strong>Lack of Cloud Security Architecture and Strategy:</strong> One of the biggest
challenges is the implementation of appropriate security architecture to
withstand cyberattacks. Unfortunately, this process is still a mystery for
many organizations.</p>
</li>
<li>
<p><strong>Insufficient Identity, Credential, Access and Key Management:</strong> In both
public and private cloud settings, CSPs and cloud consumers are required to
manage IAM without compromising security.</p>
</li>
<li>
<p><strong>Account Hijacking:</strong> Account hijacking is a threat in which malicious
attackers gain access to and abuse accounts that are highly privileged or
sensitive. In cloud environments, the accounts with the highest risks are
cloud service accounts or subscriptions.</p>
</li>
<li>
<p><strong>Insider Threat:</strong> Insider negligence is the cause of most security
incidents. Employee or contractor negligence was the root cause of most of
the reported insider incidents. Some common scenarios cited include:
misconfigured cloud servers, employees storing sensitive company data on
their own insecure personal devices and systems, and employees or other
insiders falling prey to phishing emails that led to malicious attacks on
company assets.</p>
</li>
<li>
<p><strong>Insecure Interfaces and APIs:</strong>  Poorly designed APIs could lead to misuse
or—even worse—a data breach. Broken, exposed, or hacked APIs have caused
some major data breaches.</p>
</li>
<li>
<p><strong>Limited Cloud Usage Visibility:</strong> Limited cloud usage visibility occurs
when an organization does not possess the ability to visualize and analyze
whether cloud service use within the organization is safe or malicious. This
scenario results in a self-support model called Shadow IT. one-third of all
successful security attacks on companies will come through shadow IT systems
and resources.</p>
</li>
</ol>
<h3 id="secure-cloud-software-requirements"><a class="header" href="#secure-cloud-software-requirements">Secure Cloud Software Requirements</a></h3>
<ol>
<li>
<p><strong>Top-of-the-Line Perimeter Firewall:</strong> Most firewalls are very simple—they
typically inspect a packet’s source and destination and that’s all. Some more
advanced firewalls feature stable packet inspection, which checks the integrity
of the file packets for stability issues prior to approving or rejecting the
packet.</p>
</li>
<li>
<p><strong>Intrusion Detection Systems with Event Logging:</strong> Numerous IT security
compliance standards require businesses to have a means of tracking and
recording intrusion attempts. So, for any business that wants to meet compliance
standards such as PCI or HIPAA, using IDS event logging solutions is a must.</p>
</li>
<li>
<p><strong>Internal Firewalls for Individual Applications, and Databases:</strong> While
having a strong perimeter firewall can block external attacks, internal attacks
are still a major threat. Infrastructures that lack internal firewalls to
restrict access to sensitive data and applications cannot be considered secure.</p>
</li>
<li>
<p><strong>Data-at-Rest Encryption:</strong> Encrypting the data that is stored on your
cloud infrastructure can be an effective way to keep your most sensitive
information from being accessed by the wrong party.</p>
</li>
<li>
<p><strong>Tier IV Data Centers with Strong Physical Security:</strong> The physical
hardware used to run a cloud environment represents one last opportunity for
hackers and industrial spies to steal your most important data. When allowed
direct access to the hardware that runs the cloud, hackers have free reign to
steal data or upload malware directly to your systems.</p>
</li>
</ol>
<h3 id="secure-cloud-software-testing"><a class="header" href="#secure-cloud-software-testing">Secure Cloud Software Testing</a></h3>
<ul>
<li>
<p>Cloud penetration testing is designed to assess the strengths and weaknesses
of a cloud system to improve its overall security posture. Cloud penetration
testing helps to: Identify risks, vulnerabilities, and gaps. Impact of
exploitable vulnerabilities. Determine how to leverage any access obtained
via exploitation.</p>
</li>
<li>
<p><a href="https://www.guidepointsecurity.com/education-center/cloud-penetration-testing/">More
Details</a></p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="unit-vi-advanced-techniques-in-cloud-computing"><a class="header" href="#unit-vi-advanced-techniques-in-cloud-computing">Unit VI Advanced Techniques in Cloud Computing</a></h1>
<h2 id="future-trends-in-cloud-computing"><a class="header" href="#future-trends-in-cloud-computing">Future Trends in Cloud Computing</a></h2>
<ol>
<li>
<p><strong>Hybrid/ Multi-Cloud Solutions:</strong> Hybrid cloud computing refers to using a
combination of the private cloud as well as a third-party public cloud
service. It is primarily used to allow workloads to move between private and
public clouds, giving users more flexibility with their computing needs.</p>
</li>
<li>
<p><strong>Backup And Disaster Recovery:</strong> Cyber attacks, data outages, and system
failures are a part and parcel of running a business these days. Most
businesses have dealt with their servers crashing, leading to loss of
critical data files. To ensure such issues don’t damage the organization and
its processes, backup and disaster recovery has become a trending use case
of the cloud. If Spiceworks reports are to be believed, 15% of the cloud
budget is allocated to Backup and Disaster Recovery, which is the highest
budget allocation followed by email hosting and productivity tools.</p>
</li>
<li>
<p><strong>Serverless Architecture:</strong> A serverless architecture removes all barriers
that a standard IT infrastructure would usually bring. Users don’t have to
purchase or rent the servers that they run their data on. Instead, a
third-party will handle it all for you, allowing your organization to tackle
other tasks.</p>
</li>
<li>
<p><strong>AI Platform:</strong> As technology advances, one of the most common cloud
computing trends to look forward to is AI. Tech giants are now looking into
incorporating AI to process big data to improve their business functioning.</p>
</li>
<li>
<p><strong>Cloud Security:</strong> Data theft, leakage, and deletion- security is a big
challenge even for traditional IT infrastructures. But, with more companies
moving to cloud platforms, it’s important to ensure that cloud service
providers can create an airtight security system to guarantee the safety of
their client’s data.</p>
</li>
<li>
<p><strong>IoT Platform:</strong> With a hyper-connected world, one of the most popular
cloud computing trends is the rise of IoT platforms. A study by Gartner
suggests the number of connected things in use will be going up to 25
billion by 2021 from 14.2 billion as of 2019.</p>
</li>
<li>
<p><strong>Edge Computing:</strong> It is a method of optimizing cloud computing network
system by performing data processing at the edge of the network, near the
source of the data. It works real-time on the cloud servers to process less
time-sensitive data or store data for the long term.</p>
</li>
<li>
<p><strong>DevSecOps:</strong> Cloud computing services provide users with a seamless and
simple experience in managing their data but there are many security risks
involved.  The security risk of cloud computing includes network
eavesdropping, illegal invasion, denial of service attacks, side channel
attacks, virtualization vulnerabilities, and abuse of cloud services.</p>
</li>
<li>
<p><strong>Service Mesh:</strong> Since cloud platforms are complex, it is critical to
ensure that the platform has a fast and safe communication environment. With
a service mesh, users have a dedicated layer for service-to-service
communication, making their cloud platform highly dynamic and secure.</p>
</li>
<li>
<p><strong>Open Source:</strong> This industry is moving towards a path of innovation and
collaboration. With this shift in how cloud services are managed, many
organizations are looking at adopting an Open Source cloud computing service
for their business.</p>
</li>
</ol>
<h2 id="mobile-cloud"><a class="header" href="#mobile-cloud">Mobile Cloud</a></h2>
<ul>
<li>
<p>Mobile cloud computing uses cloud computing to deliver applications to
mobile devices. These mobile apps can be deployed remotely using speed and
flexibility and development tools. Mobile cloud applications can be built or
revised quickly using cloud services. They can be delivered to many
different devices with different operating systems, computing tasks, and
data storage. Thus, users can access applications that could not otherwise
be supported.</p>
</li>
<li>
<p>Key features:</p>
<ul>
<li>Facilitates the quick development, Shared resources of mobile apps.</li>
<li>Supports a variety of development approaches and devices.</li>
<li>Improves reliability with information backed up and stored in the cloud.</li>
<li>Applications use fewer device resources because they are
cloud-supported.</li>
<li>Mobile devices are connected to services delivered on an API
architecture.</li>
</ul>
</li>
<li>
<p><a href="https://www.ibm.com/cloud/learn/what-is-mobile-cloud-computing">More
Details</a></p>
</li>
</ul>
<h2 id="automatic-cloud-computing"><a class="header" href="#automatic-cloud-computing">Automatic Cloud Computing</a></h2>
<ul>
<li>
<p>Cloud automation is a broad term that refers to processes and tools that
reduce or eliminate manual efforts used to provision and manage cloud
computing workloads and services. Organizations can apply cloud automation
to private, public and hybrid cloud environments.</p>
</li>
<li>
<p>Benefits:</p>
<ul>
<li>Improved security and resilience</li>
<li>Improved backup processes</li>
<li>Improved governance</li>
</ul>
</li>
<li>
<p><a href="https://cloud.netapp.com/blog/cloud-automation-why-where-and-how-cvo-blg">More
Details</a></p>
</li>
</ul>
<h3 id="comet-cloud"><a class="header" href="#comet-cloud">Comet Cloud</a></h3>
<ul>
<li>
<p>COMET Cloud is an Internet data storage designed for recording measured
values from selected COMET measuring instruments. The data is accessible
after the user's connection to the Internet and is displayed in a web
browser in the form of a table or graph.</p>
</li>
<li>
<p>Main features of COMETCloud</p>
<ul>
<li>display of measured values in the form of a table or graph</li>
<li>comparison of measured values of several sensors in one time period</li>
<li>storing GPS coordinates for the device position and displaying all
devices on a map</li>
<li>user-friendly display of measured values in an embedded image of a
building or technology diagram</li>
<li>user name of each device</li>
<li>insert a note for each device</li>
</ul>
</li>
<li>
<p><a href="https://www.cometsystem.com/reg-cloud#:%7E:text=COMET%20Cloud%20is%20an%20Internet,of%20a%20table%20or%20graph.">More
Details</a></p>
</li>
</ul>
<h2 id="multimedia-cloud"><a class="header" href="#multimedia-cloud">Multimedia Cloud</a></h2>
<ul>
<li>
<p>Cloud Computing opened the opportunity for media operators who serve content
providers, IPTV (Internet Protocol Television) operators and multimedia
players. When we consider multimedia players, adopting cloud computing is
often one of the important priorities in the coming years. Some media
players, for example, companies like media post-production, already utilize
these kinds of cloud computing–based service capabilities for managing the
digital delivery.</p>
</li>
<li>
<p>In the future, multimedia companies will use cloud computing first, who
started looking to move their storage requirements into cloud computing. The
cost and the investment return for these kinds of services have accelerated.</p>
</li>
</ul>
<h3 id="iptv"><a class="header" href="#iptv">IPTV</a></h3>
<ul>
<li>
<p>Internet Protocol television (IPTV) is the delivery of television content
over Internet Protocol (IP) networks. This is in contrast to delivery
through traditional terrestrial, satellite, and cable television formats.
Unlike downloaded media, IPTV offers the ability to stream the source media
continuously. As a result, a client media player can begin playing the
content (such as a TV channel) almost immediately. This is known as
streaming media.</p>
</li>
<li>
<p><a href="https://en.wikipedia.org/wiki/Internet_Protocol_television">More Details</a></p>
</li>
</ul>
<h2 id="energy-aware-cloud-computing"><a class="header" href="#energy-aware-cloud-computing">Energy Aware Cloud Computing</a></h2>
<ul>
<li>
<p>Cloud infrastructures are increasingly becoming essential components for
providing Internet services. By benefiting from economies of scale, Clouds
can efficiently manage and offer a virtually unlimited number of resources
and can minimize the costs incurred by organizations when providing Internet
services. However, as Cloud providers often rely on large data centres to
sustain their business and offer the resources that users need, the energy
consumed by Cloud infrastructures has become a key environmental and
economical concern.</p>
</li>
<li>
<p>Implementing efficient techniques, frameworks, etc. for better energy
efficiency in cloud computing is called &quot;Energy Aware Cloud Computing&quot;.</p>
</li>
<li>
<p><a href="https://www.researchgate.net/publication/324029239_Energy-aware_cloud_computing">More
Details</a></p>
</li>
</ul>
<h2 id="jungle-computing"><a class="header" href="#jungle-computing">Jungle Computing</a></h2>
<ul>
<li>
<p>Jungle computing is a form of high performance computing that distributes
computational work across cluster, grid and cloud computing.</p>
</li>
<li>
<p>The increasing complexity of the high performance computing environment has
provided a range of choices beside traditional supercomputers and clusters.
Scientists can now use grid and cloud infrastructures, in a variety of
combinations along with traditional supercomputers - all connected via fast
networks. And the emergence of many-core technologies such as GPUs, as well
as supercomputers on chip within these environments has added to the
complexity. Thus, high-performance computing can now use multiple diverse
platforms and systems simultaneously, giving rise to the term &quot;computing
jungle&quot;.</p>
</li>
</ul>
<h2 id="distributed-cloud-computing-vs-edge-computing"><a class="header" href="#distributed-cloud-computing-vs-edge-computing">Distributed Cloud Computing Vs Edge Computing</a></h2>
<ul>
<li>
<p>A distributed cloud is an architecture where multiple clouds are used to
meet compliance needs, performance requirements, or support edge computing
while being centrally managed from the public cloud provider.</p>
</li>
<li>
<p>In essence, a distributed cloud service is a public cloud that runs in
multiple locations, including:</p>
<ul>
<li>The public cloud provider’s infrastructure</li>
<li>The public cloud provider’s infrastructure</li>
<li>In another cloud provider’s data center</li>
<li>On third party or colocation center hardware</li>
</ul>
</li>
<li>
<p><strong>Edge vs Distributed Computing:</strong></p>
<p><img src="pictures/edge_vs_dist.png" alt="Edge vs Distributed Computing" /></p>
</li>
</ul>
<h2 id="containers"><a class="header" href="#containers">Containers</a></h2>
<ul>
<li>
<p>Containers are lightweight packages of your application code together with
dependencies such as specific versions of programming language runtimes and
libraries required to run your software services.</p>
</li>
<li>
<p>Containers are packages of software that contain all of the necessary
elements to run in any environment. In this way, containers virtualize the
operating system and run anywhere, from a private data center to the public
cloud or even on a developer’s personal laptop.</p>
</li>
<li>
<p>Containers make it easy to share CPU, memory, storage, and network resources
at the operating systems level and offer a logical packaging mechanism in
which applications can be abstracted from the environment in which they
actually run.</p>
</li>
<li>
<p>Benefits Of Containers:</p>
<ul>
<li>
<p><strong>Separation of responsibility:</strong> Containerization provides a clear
separation of responsibility, as developers focus on application logic
and dependencies, while IT operations teams can focus on deployment and
management instead of application details such as specific software
versions and configurations.</p>
</li>
<li>
<p><strong>Workload portability:</strong> Containers can run virtually anywhere, greatly
easing development and deployment: on Linux, Windows, and Mac operating
systems; on virtual machines or on physical servers; on a developer’s
machine or in data centers on-premises; and of course, in the public
cloud.</p>
</li>
<li>
<p><strong>Application isolation:</strong> Containers virtualize CPU, memory, storage,
and network resources at the operating system level, providing
developers with a view of the OS logically isolated from other
applications.</p>
</li>
</ul>
</li>
<li>
<p><a href="https://cloud.google.com/learn/what-are-containers">More Details</a></p>
</li>
</ul>
<h2 id="docker"><a class="header" href="#docker">Docker</a></h2>
<ul>
<li>
<p>Docker is a set of platform as a service products that use OS-level
virtualization to deliver software in packages called containers. The
service has both free and premium tiers. The software that hosts the
containers is called Docker Engine.</p>
</li>
<li>
<p><a href="https://www.docker.com/resources/what-container/">More Details</a></p>
</li>
</ul>
<h2 id="kubernetes"><a class="header" href="#kubernetes">Kubernetes</a></h2>
<ul>
<li>
<p>Kubernetes is an open-source container orchestration system for automating
software deployment, scaling, and management. Google originally designed
Kubernetes, but the Cloud Native Computing Foundation now maintains the
project.</p>
</li>
<li>
<p><a href="https://kubernetes.io/docs/concepts/overview/">More Details</a></p>
</li>
</ul>
<h2 id="introduction-to-devops"><a class="header" href="#introduction-to-devops">Introduction to DevOps</a></h2>
<ul>
<li>
<p>DevOps is the combination of cultural philosophies, practices, and tools
that increases an organization's ability to deliver applications and
services at high velocity: evolving and improving products at a faster pace
than organizations using traditional software development and infrastructure
management processes.</p>
</li>
<li>
<p>A DevOps engineer introduces processes, tools, and methodologies to balance
needs throughout the software development life cycle, from coding and
deployment, to maintenance and updates.</p>
</li>
<li>
<p><a href="https://aws.amazon.com/devops/what-is-devops/#:%7E:text=DevOps%20is%20the%20combination%20of,development%20and%20infrastructure%20management%20processes.">More
Details</a></p>
</li>
</ul>
<h2 id="iot-and-cloud-convergence"><a class="header" href="#iot-and-cloud-convergence">IoT and Cloud Convergence</a></h2>
<ul>
<li>
<p>The Internet of things describes physical objects with sensors, processing
ability, software, and other technologies that connect and exchange data
with other devices and systems over the Internet or other communications
networks.</p>
</li>
<li>
<p>The field has evolved due to the convergence of multiple technologies,
including ubiquitous computing, commodity sensors, increasingly powerful
embedded systems, and machine learning.</p>
</li>
<li>
<p><a href="https://en.wikipedia.org/wiki/Internet_of_things">More Details</a></p>
</li>
</ul>
<h3 id="the-cloud-and-iot-in-your-home"><a class="header" href="#the-cloud-and-iot-in-your-home">The Cloud and IoT in your Home</a></h3>
<ul>
<li>
<p><strong>Home cloud computing</strong> is the process of using a remote server to store,
manage and access data and applications from home. It allows users to access
their files, applications, and other digital content from any device with an
internet connection, whether it be a computer, phone, or tablet. Private
cloud computing can also be used to back up data and protect the information
in case of emergencies.</p>
</li>
<li>
<p>A lot of individuals and small businesses use home/private cloud computing
to browse, search through files and even work on projects from any device.
It’s a great alternative to setting up a server in your house because it
eliminates the need for physical storage devices that contain data.</p>
</li>
<li>
<p><a href="https://www.eiresystems.com/importance-of-home-cloud-computing/">More about home cloud
computing</a></p>
</li>
<li>
<p><strong>IoT home</strong> automation is the ability to control domestic appliances by
electronically controlled, internet-connected systems. It may include
setting complex heating and lighting systems in advance and setting alarms
and home security controls, all connected by a central hub and
remote-controlled by a mobile app.</p>
</li>
<li>
<p><a href="https://www.toptal.com/designers/interactive/smart-home-domestic-internet-of-things#:%7E:text=IoT%20home%20automation%20is%20the,controlled%20by%20a%20mobile%20app.">More about Home
IoT</a></p>
</li>
</ul>
<h3 id="the-iot-and-cloud-in-your-automobile"><a class="header" href="#the-iot-and-cloud-in-your-automobile">The IoT and cloud in your Automobile</a></h3>
<h4 id="iot-in-automobile"><a class="header" href="#iot-in-automobile">IoT in Automobile</a></h4>
<ul>
<li>
<p>“Automotive IoT” refers to the integration of such components as sensors,
gadgets, clouds, and apps into vehicles and their use as a complex system
for predictive maintenance, connection of cars, fleet management, etc.</p>
</li>
<li>
<p>Implementation of the Internet of Things for cars’ manufacturing brought the
following benefits for the producers:</p>
<ul>
<li>better data collection and analysis with the following improvement and
speed up of the whole manufacturing process;</li>
<li>avoidance of certain risks and financial losses;</li>
<li>higher industrial safety standards;</li>
<li>equipment theft monitoring, etc.</li>
</ul>
</li>
</ul>
<h4 id="cloud-in-automobile"><a class="header" href="#cloud-in-automobile">Cloud in Automobile</a></h4>
<ul>
<li>
<p>The way we interact with our car changed entirely in a few decades.
Nowadays, cloud technology in cars is present in several ways. For example,
most electric cars can exchange information with remote data centers to
inform the driver about the road and weather conditions.</p>
</li>
<li>
<p>The cloud technology in cars has a lot of possibilities. It is uniquely
suited to set up, scale, manage and update features and services efficiently
with a connected unit.</p>
</li>
<li>
<p>Automobile companies develop and adapt their connectivity software
continuously to allow their customers a better interaction between the
cloud, the car, and smartphones using infotainment as the primary interface.</p>
</li>
</ul>
<h3 id="personal"><a class="header" href="#personal">PERSONAL</a></h3>
<ul>
<li>
<p>A personal cloud is a collection of digital content and services which are
accessible from any device. The personal cloud is not a tangible entity. It is
a place which gives users the ability to store, synchronize, stream and share
content on a relative core, moving from one platform, screen and location to
another.</p>
</li>
<li>
<p><a href="https://en.wikipedia.org/wiki/Personal_cloud#:%7E:text=A%20personal%20cloud%20is%20a,screen%20and%20location%20to%20another.">More
Details</a></p>
</li>
</ul>
<h4 id="iot-in-healthcare"><a class="header" href="#iot-in-healthcare">IoT in Healthcare</a></h4>
<ul>
<li>
<p>IoT explores new dimensions of patient care through real-time health
monitoring and access to patients' health data. This data is a goldmine for
healthcare stakeholders to improve patient's health and experiences while
making revenue opportunities and improving healthcare operations.</p>
</li>
<li>
<p><a href="https://www.wipro.com/business-process/what-can-iot-do-for-healthcare-/#:%7E:text=IoT%20explores%20new%20dimensions%20of,opportunities%20and%20improving%20healthcare%20operations.">More
Details</a></p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="questions-1"><a class="header" href="#questions-1">Questions</a></h1>
<p><strong>These are the questions from SKN's recent(May 2022) prelim examinations</strong></p>
<ol>
<li>
<p><strong>Define virtualization and write down different types of virtualization.</strong>
<strong>Explain Network and Storage Virtualization in detail.</strong></p>
<ul>
<li>
<p>Virtualization in cloud computing allows a provider to virtualize
servers, storage, or other physical hardware or data center resources,
which can then, in turn, allow them to provide numerous services such as
infrastructure, software, and platforms.</p>
</li>
<li>
<p>The 7 Types of Virtualization</p>
<ol>
<li>OS Virtualization—aka Virtual Machines</li>
<li>Application-Server Virtualization</li>
<li>Application Virtualization</li>
<li>Administrative Virtualization</li>
<li>Network Virtualization</li>
<li>Hardware Virtualization</li>
<li>Storage Virtualization</li>
</ol>
</li>
<li>
<p><strong>Storage Virtualization:</strong></p>
<ul>
<li>
<p>Storage virtualization in Cloud Computing is nothing but the sharing
of physical storage into multiple storage devices which further
appears to be a single storage device. It can be also called as a
group of an available storage device which simply manages from a
central console.</p>
</li>
<li>
<p>This virtualization provides numerous benefits such as easy backup,
achieving, and recovery of the data.</p>
</li>
<li>
<p>This whole process requires very less time and works in an efficient
manner. Storage virtualization in Cloud Computing does not show the
actual complexity of the Storage Area Network (SAN). This
virtualization is applicable to all levels of SAN.</p>
</li>
</ul>
</li>
<li>
<p><strong>Network Virtualization:</strong></p>
<ul>
<li>
<p>Network Virtualization is a process of logically grouping physical
networks and making them operate as single or multiple independent
networks called Virtual Networks.</p>
</li>
<li>
<p>Tools for Network Virtualization :</p>
<ol>
<li><strong>Physical switch OS:</strong> It is where the OS must have the
functionality of network virtualization.</li>
<li><strong>Hypervisor:</strong> It is which uses third-party software or
built-in networking and the functionalities of network
virtualization.</li>
</ol>
</li>
<li>
<p>Advantages of Network Virtualization :</p>
<ol>
<li>Improves manageability</li>
<li>Improves utilization</li>
<li>Enhances performance</li>
<li>Enhances security</li>
</ol>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Explain virtualization in grid.</strong></p>
<ul>
<li>
<p><strong>NEEDS REFACTORING</strong></p>
</li>
<li>
<p>Virtualization allows addressing multiple problems in Grid systems, such
as coping with the heterogeneity of Grid resources, the difference in
software stacks, and enhanced features in resource management such as
more general check pointing or migration models. Adopting virtualization
in smart ways gets us closer to real Grid computing with more ﬂexibility
in the type of applications and the resources to use.</p>
</li>
</ul>
</li>
</ol>
<!-- TODO: Virtualization in grid -->
<ol start="3">
<li>
<p><strong>Explain Virtual Clustering in detail.</strong></p>
<ul>
<li><strong>NEEDS REFACTORING</strong></li>
</ul>
</li>
<li>
<p><strong>Explain CPU virtualization in detail.</strong></p>
<ul>
<li>
<p>CPU Virtualization is a hardware feature found in all current AMD &amp;
Intel CPUs that allows a single processor to act as if it was multiple
individual CPUs.This allows an operating system to more effectively &amp;
efficiently utilize the CPU power in the computer so that it runs
faster.</p>
</li>
<li>
<p>CPU Virtualization improves performance and efficiency to a greater
extent because virtual machines work on a single CPU, sharing resources
is actually like using multiple processors at the same time. This saves
Cost and Money.</p>
</li>
<li>
<p>Types of CPU Virtualization</p>
<ol>
<li>
<p><strong>Hardware-assisted CPU Virtualization :</strong> Hardware supports CPU
Virtualization through certain processors like Guest User. This Uses
different versions of code and the mode is known as a Guest mode.</p>
</li>
<li>
<p><strong>Software-based CPU Virtualization :</strong> This type of CPU
Virtualization is software-based and it helps application code to get
executed on a processor.</p>
</li>
<li>
<p><strong>Virtualization and Processor-Specific behavior:</strong> Although this
software virtualizes the CPU, the virtual machine can detect the model
of a processor on which it is running, processor models may differ in
CPU features they offer and applications running on these CPUs may use
these features.</p>
</li>
</ol>
</li>
<li>
<p><a href="u2.1.html#cpu-virtualization">Need more info?</a></p>
</li>
</ul>
</li>
<li>
<p><strong>Explain in detail Amazon Web Services &amp; its components.</strong></p>
<ul>
<li>
<p>Amazon Web Services, Inc. is a subsidiary of Amazon that provides
on-demand cloud computing platforms and APIs to individuals, companies,
and governments, on a metered pay-as-you-go basis. These cloud computing
web services provide distributed computing processing capacity and
software tools via AWS server farms.</p>
</li>
<li>
<p>Amazon Web Services (AWS) is the world’s most comprehensive and broadly
adopted cloud platform, offering over 200 fully featured services from
data centers globally. Millions of customers—including the
fastest-growing startups, largest enterprises, and leading government
agencies—are using AWS to lower costs, become more agile, and innovate
faster.</p>
</li>
<li>
<p>AWS Components:</p>
<ol>
<li>
<p><strong>Data Management and Data Transfer:</strong> To run HPC applications in
the AWS cloud, you need to move the required data into the cloud. There
are several data transport solutions designed to securely transfer huge
amounts of data. This overcomes issues like a long time for transfer,
high network costs, and security concerns. Also, you can automate the
movement of data between the AWS cloud and on-premises storage. There
are options for establishing a private connection to the AWS from your
premises. This increases bandwidth to provide more throughput, reduces
the cost of the network, and provides a consistent network experience.</p>
</li>
<li>
<p><strong>Compute &amp; Networking:</strong> There are several compute instances types
that can be customized according to your needs. It also handles
monitoring your application and adjusting its capacity for maintaining a
steady and predictable performance at an affordable cost. Also, setting
up application scaling across multiple services for multiple resources
takes a few minutes. Enhanced networking options from AWS allow
achieving lower inter-instance latency and higher bandwidth.</p>
</li>
<li>
<p><strong>Storage:</strong> When looking for an HPC solution, you need to consider
the storage options and cost. There are several flexible blocks, object,
and file storage options in AWS services that allow permanent and
transient data storage. It allows allocating storage volumes according
to the size you need. You can store and access and data type over the
cloud without doing a data migration project. Also, with AWS services,
you can transfer your workload to the cloud from on-premises.</p>
</li>
<li>
<p><strong>Automation and Orchestration:</strong> For using the infrastructure
efficiently, you need to automate scheduling submitted jobs and the job
submission process. AWS services allow you to run thousands of batch
computing jobs through the dynamic provision of the computer resources
on the basis of the requirements.</p>
</li>
<li>
<p><strong>Operations and Management:</strong> As a system administrator, you are
responsible for avoiding cost overruns and monitoring the
infrastructure. There are several management and monitoring services
that allow you to optimize utilization of resources, monitor the
application, get a complete view of operational health, and respond to
the performance changes.</p>
</li>
<li>
<p><strong>Visualization:</strong> With the AWS services, you can easily visualize
the engineering simulations’ results without moving huge amounts of
data. Now, you can access the interactive applications remotely over a
standard network and deliver application sessions to any workstation.</p>
</li>
<li>
<p><strong>Security and Compliance:</strong> For running applications on the cloud,
you need to have an understanding of regulatory compliance and security
management. There are several quick-launch templates and security
related services offered by AWS that helps in protecting data and
customer privacy by putting strong safeguards in the AWS
infrastructure.</p>
</li>
</ol>
</li>
</ul>
</li>
<li>
<p><strong>Explain in detail Elastic Cloud Computing(EC2).</strong></p>
<ul>
<li>
<p><strong>Amazon Elastic Compute Cloud</strong> is a part of Amazon.com's cloud-computing
platform, Amazon Web Services, that allows users to rent virtual computers
on which to run their own computer applications.</p>
</li>
<li>
<p>Features of Amazon EC2:</p>
<ul>
<li><strong>Functionality:</strong> EC2 provides its users a true virtual computing
platform, where they can various operations and even launch another
EC2 instance from this virtually created environment. This will
increase the security of these virtual devices. Not only creating
but also EC2 allows us to customize our environment as per our
requirements, at any point of time during the life span of this
virtual machine. Amazon EC2 itself comes with a set of default
AMI(Amazon Machine Image) options supporting various operating
systems along with some pre-configured resources like RAM, ROM,
storage, etc. Besides these AMI options, we can also create an AMI
curated with the combination of default and user-defined
configurations. And for future purposes, we can store this
user-defined AMI, so that next time, the user won’t have to
re-configure a new AMI from scratch. Rather than this whole process,
the user can simply use the older reference while creating a new EC2
machine.</li>
<li><strong>Operating Systems:</strong> Amazon EC2 includes a wide range of operating
systems to choose from while selecting your AMI. Not only these
selected options, but users are also even given the privileges to
upload their own operating systems and opt for that while selecting
AMI during launching an EC2 instance. Currently, AWS has the
following most preferred set of operating systems available on the
EC2 console.
<ul>
<li>Amazon Linux</li>
<li>Windows Server</li>
<li>Ubuntu Server</li>
<li>SUSE Linux</li>
<li>Red Hat Linux</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Explain in detail Azure core concepts.</strong></p>
<ul>
<li>
<p>Microsoft Azure, often referred to as Azure, is a cloud computing service
operated by Microsoft for application management via Microsoft-managed data
centers.</p>
</li>
<li>
<p>Azure core concepts:</p>
</li>
</ul>
</li>
</ol>
<!-- TABLE -->
<table><thead><tr><th>Concept Name</th><th>Description</th></tr></thead><tbody>
<tr><td><strong>Regions</strong></td><td>Azure is a global cloud platform which is available across various regions around the world. When you request a service, application, or VM in Azure, you are first asked to specify a region. The selected region represents datacenter where your application runs.</td></tr>
<tr><td><strong>Datacenter</strong></td><td>In Azure, you can deploy your applications into a variety of data centers around the globe. So, it is advisable to select a region which is closer to most of your customers. It helps you to reduce latency in network requests.</td></tr>
<tr><td><strong>Azure portal</strong></td><td>The Azure portal is a web-based application which can be used to create, manage and remove Azure resource and services. It is located at https://portal.azure.com.</td></tr>
<tr><td><strong>Resources</strong></td><td>Azure resource is an individual computer, networking data or app hosting services which charged individually. Some common resources are virtual machines( VM), storage account, or SQL databases.</td></tr>
<tr><td><strong>Resource groups</strong></td><td>An Azure resource group is a container which holds related resource for an Azure solution. It may include every resource or just resource which you wants to manage.</td></tr>
<tr><td><strong>Resource Manager templates</strong></td><td>It is a JSON which defines one or more resource to deploy to a resource group. It also establishes dependencies between deployed resources.</td></tr>
<tr><td><strong>Automation:</strong></td><td>Azure allows you to automate the process of creating, managing and deleting resource by using PowerShell or the Azure command-line Interface(CLI).</td></tr>
<tr><td><strong>Azure PowerShell</strong></td><td>PowerShell is a set of modules that offer cmdlets to manage Azure. In most cases, you are allowed to use, the cmdlets command for the same tasks which you are performing in the Azure portal.</td></tr>
<tr><td><strong>Azure command-line interface(CLI)</strong></td><td>The Azure CLI is a tool that you can use to create, manage, and remove Azure resources from the command line.</td></tr>
<tr><td><strong>REST APIs</strong></td><td>Azure is built on a set of REST APIs help you perform the same operation that you do in Azure portal Ul. It allows your Azure resources and apps to be manipulated via any third party software application.</td></tr>
</tbody></table>
<ol start="8">
<li>
<p><strong>Explain in detail cloud computing applications:</strong></p>
<ul>
<li>
<p><strong>Healthcare:</strong> Cloud computing in healthcare describes the practice of
implementing remote servers accessed via the internet to store, manage
and process healthcare-related data. This is in contrast to establishing
an on-site data center with servers, or hosting the data on a personal
computer.</p>
<ul>
<li>
<p><strong>ECG Analysis in the cloud:</strong></p>
<ul>
<li>
<p><strong>ECG analysis in cloud computing</strong>: cloud computing
technologies allows the remote monitoring of a patient's heart
beat data. Through this way the patient at risk can be
constantly monitored without going to the hospital for ECG
analysis. At the same time the Doctor's can instantly be
notified with cases that need's their attention.</p>
</li>
<li>
<p>An ECG is just a visual image of a record of the electrical
activity of the heart muscle as it varies over time, typically
printed on paper for easier study. Similarly, like other
muscles, the heart contracts in response to electrical
depolarization caused in the muscle cells. When it's the time of
day, it's the amount of the electrical activity, when amplified
and registered for just a few seconds that we call a heart
rhythm.</p>
</li>
<li>
<p>With ECG data collection and tracking, it's possible to test for
chest pain, low-grade heart rhythm disturbances, arrhythmias,
and more. An E-G (electrocardiogram) is the electrical
expression of the contractile movement of the myocardium.</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Biology:</strong> Cloud computing is an emerging technology that provides
various computing services on demand. It provides convenient access to a
shared pool of higher-level services and other system resources.
Nowadays, cloud computing has a great significance in the fields of
geology, biology, and other scientific research areas.</p>
<ul>
<li>
<p><strong>Protein Structure Prediction:</strong></p>
<ul>
<li>
<p>Protein structure prediction is the best example in research
area that makes use of cloud applications for its computation
and storage.</p>
</li>
<li>
<p>A protein is composed of long chains of amino acids joined
together by peptide bonds. The various structures of protein
help in the designing of new drugs and the various sequences of
proteins from its three-dimensional structure in predictive form
is known as a Protein structure prediction.</p>
</li>
<li>
<p>Firstly primary structures of proteins are formed and then
prediction of the secondary, tertiary and quaternary structures
are done from the primary one. In this way predictions of
protein structures are done. Protein structure prediction also
makes use of various other technologies like artificial neural
networks, artificial intelligence, machine learning and
probabilistic techniques, also holds great importance in fields
like theoretical chemistry and bioinformatics.</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Explain different types of risks in cloud computing.</strong></p>
<ul>
<li>
<p>In many ways, the security threats facing today’s traditional data
center environments overlap with those of a cloud computing environment.
On both sides, cybercriminals aim to take advantage of vulnerabilities
found in software.</p>
</li>
<li>
<p>There are several security risks to consider when making the switch to
cloud computing. Here are 5 of the top security risks your organization
should be aware of:</p>
</li>
</ul>
<ol>
<li>
<p><strong>Data Loss:</strong> Data loss is the most common cloud security risks of
cloud computing. It is also known as data leakage. Data loss is the process
in which data is being deleted, corrupted, and unreadable by a user,
software, or application. In a cloud computing environment, data loss occurs
when our sensitive data is somebody else's hands, one or more data elements
can not be utilized by the data owner, hard disk is not working properly,
and software is not updated.</p>
</li>
<li>
<p><strong>Hacked Interfaces and Insecure APIs:</strong> As we all know, cloud computing
is completely depends on Internet, so it is compulsory to protect interfaces
and APIs that are used by external users. APIs are the easiest way to
communicate with most of the cloud services. In cloud computing, few
services are available in the public domain. These services can be accessed
by third parties, so there may be a chance that these services easily harmed
and hacked by hackers.</p>
</li>
<li>
<p><strong>Data Breach:</strong> Data Breach is the process in which the confidential
data is viewed, accessed, or stolen by the third party without any
authorization, so organization's data is hacked by the hackers.</p>
</li>
<li>
<p><strong>Vendor lock-in:</strong> Vendor lock-in is the of the biggest security risks
in cloud computing. Organizations may face problems when transferring their
services from one vendor to another. As different vendors provide different
platforms, that can cause difficulty moving one cloud to another.</p>
</li>
<li>
<p><strong>Increased complexity strains IT staff:</strong> Migrating, integrating, and
operating the cloud services is complex for the IT staff. IT staff must
require the extra capability and skills to manage, integrate, and maintain
the data to the cloud.</p>
</li>
<li>
<p><strong>Spectre &amp; Meltdown:</strong> Spectre &amp; Meltdown allows programs to view and
steal data which is currently processed on computer. It can run on personal
computers, mobile devices, and in the cloud. It can store the password, your
personal information such as images, emails, and business documents in the
memory of other running programs.</p>
</li>
<li>
<p><strong>Denial of Service (DoS) attacks:</strong> Denial of service (DoS) attacks
occur when the system receives too much traffic to buffer the server.
Mostly, DoS attackers target web servers of large organizations such as
banking sectors, media companies, and government organizations. To recover
the lost data, DoS attackers charge a great deal of time and money to handle
the data.</p>
</li>
<li>
<p><strong>Account hijacking:</strong> Account hijacking is a serious security risk in
cloud computing. It is the process in which individual user's or
organization's cloud account (bank account, e-mail account, and social media
account) is stolen by hackers. The hackers use the stolen account to perform
unauthorized activities.</p>
</li>
</ol>
</li>
<li>
<p><strong>Explain in detail cloud security services:</strong> <em>Confidentiality,</em>
<em>Integrity, &amp;</em> <em>Availability</em></p>
<ul>
<li>
<p>The three letters in &quot;CIA triad&quot; stand for Confidentiality, Integrity,
and Availability. The CIA triad is a common model that forms the basis
for the development of security systems. They are used for finding
vulnerabilities and methods for creating solutions.</p>
</li>
<li>
<p>The core principles of information security and data governance—data
confidentiality, integrity, and availability (known as the CIA
triad)—also apply to the cloud:</p>
<ul>
<li><strong>Confidentiality:</strong> protecting the data from unauthorized access
and disclosure</li>
<li><strong>Integrity:</strong> safeguard the data from unauthorized modification so
it can be trusted</li>
<li><strong>Availability:</strong> ensuring the data is fully available and
accessible when it’s needed</li>
</ul>
</li>
<li>
<p><a href="u2.3.html#data-security-in-cloud">More details about CIA</a></p>
</li>
</ul>
</li>
<li>
<p><strong>Explain in detail different types of risks in Cloud Computing.</strong></p>
<ul>
<li>Refer question 9</li>
</ul>
</li>
<li>
<p><strong>Explain need of secure cloud software requirements.</strong></p>
<ul>
<li>
<p>You need a secure way to immediately access your data. Cloud security
ensures your data and applications are readily available to authorized
users. You'll always have a reliable method to access your cloud
applications and information, helping you quickly take action on any
potential security issues.</p>
</li>
<li>
<p>Secure cloud software requirements:</p>
</li>
</ul>
<ol>
<li>
<p><strong>Top-of-the-Line Perimeter Firewall:</strong> Most firewalls are very
simple—they typically inspect a packet’s source and destination and that’s
all. Some more advanced firewalls feature stable packet inspection, which
checks the integrity of the file packets for stability issues prior to
approving or rejecting the packet.</p>
</li>
<li>
<p><strong>Intrusion Detection Systems with Event Logging:</strong> Numerous IT security
compliance standards require businesses to have a means of tracking and
recording intrusion attempts. So, for any business that wants to meet
compliance standards such as PCI or HIPAA, using IDS event logging solutions
is a must.</p>
</li>
<li>
<p><strong>Internal Firewalls for Individual Applications, and Databases:</strong> While
having a strong perimeter firewall can block external attacks, internal
attacks are still a major threat. Infrastructures that lack internal
firewalls to restrict access to sensitive data and applications cannot be
considered secure.</p>
</li>
<li>
<p><strong>Data-at-Rest Encryption:</strong> Encrypting the data that is stored on your
cloud infrastructure can be an effective way to keep your most sensitive
information from being accessed by the wrong party.</p>
</li>
<li>
<p><strong>Tier IV Data Centers with Strong Physical Security:</strong> The physical
hardware used to run a cloud environment represents one last opportunity for
hackers and industrial spies to steal your most important data. When allowed
direct access to the hardware that runs the cloud, hackers have free reign
to steal data or upload malware directly to your systems.</p>
</li>
</ol>
</li>
<li>
<p><strong>Explain future trends in cloud computing.</strong></p>
<ul>
<li>
<p>Future Trends in Cloud Computing</p>
<ol>
<li>
<p><strong>Hybrid/ Multi-Cloud Solutions:</strong> Hybrid cloud computing refers to
using a combination of the private cloud as well as a third-party public
cloud service. It is primarily used to allow workloads to move between
private and public clouds, giving users more flexibility with their
computing needs.</p>
</li>
<li>
<p><strong>Backup And Disaster Recovery:</strong> Cyber attacks, data outages, and
system failures are a part and parcel of running a business these days.
Most businesses have dealt with their servers crashing, leading to loss
of critical data files. To ensure such issues don’t damage the
organization and its processes, backup and disaster recovery has become
a trending use case of the cloud. If Spiceworks reports are to be
believed, 15% of the cloud budget is allocated to Backup and Disaster
Recovery, which is the highest budget allocation followed by email
hosting and productivity tools.</p>
</li>
<li>
<p><strong>Serverless Architecture:</strong> A serverless architecture removes all
barriers that a standard IT infrastructure would usually bring. Users
don’t have to purchase or rent the servers that they run their data on.
Instead, a third-party will handle it all for you, allowing your
organization to tackle other tasks.</p>
</li>
<li>
<p><strong>AI Platform:</strong> As technology advances, one of the most common
cloud computing trends to look forward to is AI. Tech giants are now
looking into incorporating AI to process big data to improve their
business functioning.</p>
</li>
<li>
<p><strong>Cloud Security:</strong> Data theft, leakage, and deletion- security is a
big challenge even for traditional IT infrastructures. But, with more
companies moving to cloud platforms, it’s important to ensure that cloud
service providers can create an airtight security system to guarantee
the safety of their client’s data.</p>
</li>
<li>
<p><strong>IoT Platform:</strong> With a hyper-connected world, one of the most
popular cloud computing trends is the rise of IoT platforms. A study by
Gartner suggests the number of connected things in use will be going up
to 25 billion by 2021 from 14.2 billion as of 2019.</p>
</li>
<li>
<p><strong>Edge Computing:</strong> It is a method of optimizing cloud computing
network system by performing data processing at the edge of the network,
near the source of the data. It works real-time on the cloud servers to
process less time-sensitive data or store data for the long term.</p>
</li>
<li>
<p><strong>DevSecOps:</strong> Cloud computing services provide users with a
seamless and simple experience in managing their data but there are many
security risks involved.  The security risk of cloud computing includes
network eavesdropping, illegal invasion, denial of service attacks, side
channel attacks, virtualization vulnerabilities, and abuse of cloud
services.</p>
</li>
<li>
<p><strong>Service Mesh:</strong> Since cloud platforms are complex, it is critical
to ensure that the platform has a fast and safe communication
environment. With a service mesh, users have a dedicated layer for
service-to-service communication, making their cloud platform highly
dynamic and secure.</p>
</li>
<li>
<p><strong>Open Source:</strong> This industry is moving towards a path of
innovation and collaboration. With this shift in how cloud services are
managed, many organizations are looking at adopting an Open Source
cloud computing service for their business.</p>
</li>
</ol>
</li>
</ul>
</li>
<li>
<p><strong>Explain Docker and Kubernetes in detail.</strong></p>
<ul>
<li>
<p>Docker is a set of platform as a service products that use OS-level
virtualization to deliver software in packages called containers. The
service has both free and premium tiers. The software that hosts the
containers is called Docker Engine.</p>
</li>
<li>
<p><a href="https://www.geeksforgeeks.org/introduction-to-docker/">More Details</a></p>
</li>
<li>
<p>Kubernetes is an open-source container orchestration system for
automating software deployment, scaling, and management. Google
originally designed Kubernetes, but the Cloud Native Computing
Foundation now maintains the project.</p>
</li>
<li>
<p><a href="https://kubernetes.io/docs/concepts/overview/">More Details</a></p>
</li>
</ul>
</li>
<li>
<p><strong>Explain Mobile Cloud in detail:</strong> <em>Key requirements,</em> <em>Automatic cloud
computing, &amp;</em> <em>Comet cloud</em></p>
<ul>
<li>
<p>Key requirements:</p>
<ul>
<li>
<p>Cloud infrastructure: Cloud infrastructure is a specific form of
information architecture that is used to store data.</p>
</li>
<li>
<p>Data cache: In this, the data can be locally cached.</p>
</li>
<li>
<p>User Accommodation: Scope of accommodating different user
requirements in cloud app development is available in mobile Cloud
Computing.</p>
</li>
<li>
<p>Easy Access: It is easily accessed from desktop or mobile devices
alike.</p>
</li>
<li>
<p>Cloud Apps facilitate to provide access to a whole new range of
services.</p>
</li>
</ul>
</li>
<li>
<p><a href="u2.4.html#mobile-cloud">Refer for Mobile Cloud</a></p>
</li>
<li>
<p><a href="u2.4.html#automatic-cloud-computing">Refer for Automatic Cloud Computing</a></p>
</li>
<li>
<p><a href="u2.4.html#comet-cloud">Refer for Comet Cloud</a></p>
</li>
</ul>
</li>
<li>
<p><strong>Explain the IoT and cloud in automobile.</strong></p>
<ul>
<li><a href="u2.4.html#the-iot-and-cloud-in-your-automobile">Refer for IoT and cloud in your automobile</a></li>
</ul>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="data-science-and-big-data-1"><a class="header" href="#data-science-and-big-data-1">Data Science and Big Data</a></h1>
<ul>
<li>
<p>Unit III <strong>Big Data Analytics Life Cycle</strong></p>
<p>Introduction to Big Data, sources of Big Data, Data Analytic Lifecycle: Introduction, Phase 1:
Discovery, Phase 2: Data Preparation, Phase 3: Model Planning, Phase 4: Model Building, Phase 5:
Communication results, Phase 6: Operation alize.</p>
</li>
<li>
<p>Unit IV <strong>Predictive Big Data Analytics with Python</strong></p>
<p>Introduction, Essential Python Libraries, Basic examples. Data Preprocessing: Removing
Duplicates, Transformation of Data using function or mapping, replacing values, Handling Missing
Data. Analytics Types: Predictive, Descriptive and Prescriptive. Association Rules: Apriori
Algorithm, FP growth. Regression: Linear Regression, Logistic Regression. Classification: Naïve
Bayes, Decision Trees. Introduction to Scikit-learn, Installations, Dataset, mat plotlib, filling
missing values, Regression and Classification using Scikit-learn.</p>
</li>
<li>
<p>Unit V <strong>Big Data Analytics and Model Evaluation</strong></p>
<p>Clustering Algorithms: K-Means, Hierarchical Clustering, Time-series analysis. Introduction to
Text Analysis: Text-preprocessing, Bag of words, TF-IDF and topics. Need and Introduction to
social network analysis, Introduction to business analysis. Model Evaluation and Selection: Metrics
for Evaluating Classifier Performance, Holdout Method and Random Sub sampling, Parameter
Tuning and Optimization, Result Interpretation, Clustering and Time-series analysis using Scikit-
learn, sklearn. metrics, Confusion matrix, AUC-ROC Curves, Elbow plot.</p>
</li>
<li>
<p>Unit VI <strong>Data Visualization and Hadoop</strong></p>
<p>Introduction to Data Visualization, Challenges to Big data visualization, Types of data visualization,
Data Visualization Techniques, Visualizing Big Data, Tools used in Data Visualization, Hadoop
ecosystem, Map Reduce, Pig, Hive, Analytical techniques used in Big data visualization. Data
Visualization using Python: Line plot, Scatter plot, Histogram, Density plot, Box- plot.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="unit-iii-big-data-analytics-life-cycle"><a class="header" href="#unit-iii-big-data-analytics-life-cycle">Unit III: Big Data Analytics Life Cycle</a></h1>
<h2 id="introduction-to-big-data"><a class="header" href="#introduction-to-big-data">Introduction to Big Data</a></h2>
<p>Big data refers to data sets that are too large or complex to be dealt with by
traditional data-processing application software. Data with many fields offer
greater statistical power, while data with higher complexity may lead to a
higher false discovery rate.</p>
<ul>
<li>
<p>Five Vs of big data:</p>
<ol>
<li>
<p><strong>Volume:</strong>	The amount of data matters. With big data, you’ll have to
process high volumes of low-density, unstructured data. This can be data of
unknown value, such as Twitter data feeds, clickstreams on a web page or a
mobile app, or sensor-enabled equipment. For some organizations, this might
be tens of terabytes of data. For others, it may be hundreds of petabytes.</p>
</li>
<li>
<p><strong>Velocity:</strong>	Velocity is the fast rate at which data is received and
(perhaps) acted on. Normally, the highest velocity of data streams directly
into memory versus being written to disk. Some internet-enabled smart
products operate in real time or near real time and will require real-time
evaluation and action.</p>
</li>
<li>
<p><strong>Variety:</strong>	Variety refers to the many types of data that are
available. Traditional data types were structured and fit neatly in a
relational database. With the rise of big data, data comes in new
unstructured data types. Unstructured and semistructured data types, such as
text, audio, and video, require additional preprocessing to derive meaning
and support metadata.</p>
</li>
<li>
<p><strong>Veracity:</strong> It refers to inconsistencies and uncertainty in data, that
is data which is available can sometimes get messy and quality and accuracy
are difficult to control. Big Data is also variable because of the multitude
of data dimensions resulting from multiple disparate data types and sources.
Example: Data in bulk could create confusion whereas less amount of data
could convey half or Incomplete Information.</p>
</li>
<li>
<p><strong>Value:</strong> After having the 4 V’s into account there comes one more V
which stands for Value!. The bulk of Data having no Value is of no good to
the company, unless you turn it into something useful. Data in itself is of
no use or importance but it needs to be converted into something valuable to
extract Information. Hence, you can state that Value! is the most important
V of all the 5V’s.</p>
</li>
</ol>
</li>
<li>
<p>Big data benefits:</p>
<ul>
<li>Big data makes it possible for you to gain more complete answers because
you have more information.</li>
<li>More complete answers mean more confidence in the data—which means a
completely different approach to tackling problems.</li>
</ul>
</li>
</ul>
<h2 id="sources-of-big-data"><a class="header" href="#sources-of-big-data">Sources of Big Data</a></h2>
<p>The bulk of big data generated comes from three primary sources: social data,
machine data and transactional data. In addition, companies need to make the
distinction between data which is generated internally, that is to say it
resides behind a company’s firewall, and externally data generated which needs
to be imported into a system. Whether data is unstructured or structured is also
an important factor. Unstructured data does not have a pre-defined data model
and therefore requires more resources to make sense of it.</p>
<ul>
<li>
<p>The three primary sources of  Big Data</p>
<ul>
<li>
<p><strong>Social data</strong> comes from the Likes, Tweets &amp; Retweets, Comments, Video
Uploads, and general media that are uploaded and shared via the world’s
favorite social media platforms. This kind of data provides invaluable
insights into consumer behavior and sentiment and can be enormously
influential in marketing analytics. The public web is another good
source of social data, and tools like Google Trends can be used to good
effect to increase the volume of big data.</p>
</li>
<li>
<p><strong>Machine data</strong> is defined as information which is generated by
industrial equipment, sensors that are installed in machinery, and even
web logs which track user behavior. This type of data is expected to
grow exponentially as the internet of things grows ever more pervasive
and expands around the world. Sensors such as medical devices, smart
meters, road cameras, satellites, games and the rapidly growing Internet
Of Things will deliver high velocity, value, volume and variety of data
in the very near future.</p>
</li>
<li>
<p><strong>Transactional data</strong> is generated from all the daily transactions that
take place both online and offline. Invoices, payment orders, storage
records, delivery receipts – all are characterized as transactional data
yet data alone is almost meaningless, and most organizations struggle to
make sense of the data that they are generating and how it can be put to
good use.</p>
</li>
</ul>
</li>
</ul>
<h2 id="data-analytic-lifecycle"><a class="header" href="#data-analytic-lifecycle">Data Analytic Lifecycle:</a></h2>
<p>The Data analytic lifecycle is designed for Big Data problems and data science
projects. The cycle is iterative to represent real project. To address the
distinct requirements for performing analysis on Big Data, step – by – step
methodology is needed to organize the activities and tasks involved with
acquiring, processing, analyzing, and repurposing data.</p>
<ul>
<li>
<p>There are six phases in Data Analytics Lifecycle:</p>
<p><img src="pictures/phases.jpg" alt="Phases of Data Analytics Lifecycle" /></p>
<ol>
<li><strong>Discovery:</strong> The data science team learn and investigate the problem.
Develop context and understanding. Come to know about data sources needed
and available for the project. The team formulates initial hypothesis that
can be later tested with data.</li>
<li><strong>Data Preparation:</strong> Steps to explore, preprocess, and condition data
prior to modeling and analysis. It requires the presence of an analytic
sandbox, the team execute, load, and transform, to get data into the
sandbox. Data preparation tasks are likely to be performed multiple times
and not in predefined order. Several tools commonly used for this phase are
– Hadoop, Alpine Miner, Open Refine, etc.</li>
<li><strong>Model Planning:</strong> Team explores data to learn about relationships
between variables and subsequently, selects key variables and the most
suitable models. In this phase, data science team develop data sets for
training, testing, and production purposes. Team builds and executes models
based on the work done in the model planning phase. Several tools commonly
used for this phase are – Matlab, STASTICA.</li>
<li><strong>Model Building:</strong> Team develops datasets for testing, training, and
production purposes. Team also considers whether its existing tools will
suffice for running the models or if they need more robust environment for
executing models. Free or open-source tools – Rand PL/R, Octave, WEKA.
Commercial tools – Matlab , STASTICA.</li>
<li><strong>Communication Results:</strong> After executing model team need to compare
outcomes of modeling to criteria established for success and failure. Team
considers how best to articulate findings and outcomes to various team
members and stakeholders, taking into account warning, assumptions. Team
should identify key findings, quantify business value, and develop narrative
to summarize and convey findings to stakeholders.</li>
<li><strong>Operationalize:</strong> The team communicates benefits of project more
broadly and sets up pilot project to deploy work in controlled way before
broadening the work to full enterprise of users. This approach enables team
to learn about performance and related constraints of the model in
production environment on small scale  , and make adjustments before full
deployment. The team delivers final reports, briefings, codes. Free or open
source tools – Octave, WEKA, SQL, MADlib.</li>
</ol>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="unit-iv-predictive-big-data-analytics-with-python"><a class="header" href="#unit-iv-predictive-big-data-analytics-with-python">Unit IV: Predictive Big Data Analytics with Python</a></h1>
<h2 id="introduction-1"><a class="header" href="#introduction-1">Introduction</a></h2>
<p>Predictive analytics is a branch of advanced analytics that makes predictions
about future outcomes using historical data combined with statistical modeling,
data mining techniques and machine learning. Companies employ predictive
analytics to find patterns in this data to identify risks and opportunities.</p>
<p>Predictive analytics is often associated with big data and data science.
Companies today are swimming in data that resides across transactional
databases, equipment log files, images, video, sensors or other data sources. To
gain insights from this data, data scientists use deep learning and machine
learning algorithms to find patterns and make predictions about future events.
These include linear and nonlinear regression, neural networks, support vector
machines and decision trees. Learnings obtained through predictive analytics can
then be used further within prescriptive analytics to drive actions based on
predictive insights.</p>
<p>Python and R are two of the languages that are most commonly used for developing
predictive analytics applications.</p>
<h2 id="essential-python-libraries"><a class="header" href="#essential-python-libraries">Essential Python Libraries</a></h2>
<ul>
<li>
<p><strong>Numpy and Scipy:</strong> Fundamental Scientific Computing NumPy stands for
Numerical Python. The most powerful feature of NumPy is n-dimensional array.
This library also contains basic linear algebra functions, Fourier
transforms, advanced random number capabilities and tools for integration
with other low level languages like Fortran, C and C++. SciPy stands for
Scientific Python. It is built on NumPy. Scipy is one of the most useful
library for variety of high level science and engineering modules like
discrete Fourier transform, Linear Algebra, Optimization and Sparse
matrices.</p>
</li>
<li>
<p><strong>Pandas:</strong> Data Manipulation and Analysis Pandas for structured data
operations and manipulations. It is extensively used for data munging and
preparation. Pandas were added relatively recently to Python and have been
instrumental in boosting Python’s usage in data scientist community.</p>
</li>
<li>
<p><strong>Matplotlib:</strong> Plotting and Visualization Matplotlib for plotting vast
variety of graphs, starting from histograms to line plots to heat plots..
You can use Pylab feature in ipython notebook (ipython notebook –pylab =
inline) to use these plotting features inline. If you ignore the inline
option, then pylab converts ipython environment to an environment, very
similar to Matlab.</p>
</li>
<li>
<p><strong>Scikit-learn:</strong> Machine Learning and Data Mining Scikit Learn for machine
learning. Built on NumPy, SciPy and matplotlib, this library contains a lot
of efficient tools for machine learning and statistical modeling including
classification, regression, clustering and dimensional reduction.</p>
</li>
<li>
<p><strong>StatsModels:</strong> Statistical Modeling, Testing, and Analysis Statsmodels for
statistical modeling. It is a Python module that allows users to explore
data, estimate statistical models, and perform statistical tests. An
extensive list of descriptive statistics, statistical tests, plotting
functions, and result statistics are available for different types of data
and each estimator.</p>
</li>
<li>
<p><strong>Seaborn:</strong> For Statistical Data Visualization Seaborn for statistical data
visualization.  It is a library for making attractive and informative
statistical graphics in Python. It is based on matplotlib. Seaborn aims to
make visualization a central part of exploring and understanding data.</p>
</li>
</ul>
<h2 id="basic-examples"><a class="header" href="#basic-examples">Basic examples</a></h2>
<ol>
<li>Predicting buying behavior in retail</li>
<li>Detecting sickness in healthcare</li>
<li>Curating content in entertainment</li>
<li>Predicting maintenance in manufacturing</li>
<li>Detecting fraud in cybersecurity</li>
<li>Predicting performance in sports</li>
<li>Forecasting patterns in weather</li>
</ol>
<h2 id="data-preprocessing"><a class="header" href="#data-preprocessing">Data Preprocessing:</a></h2>
<p>Data preprocessing is a data mining technique which is used to transform the raw
data in a useful and efficient format.</p>
<!-- TODO: data preprocessing -->
<p><strong>NEEDS REFACTORING</strong></p>
<h3 id="removing-duplicates"><a class="header" href="#removing-duplicates">Removing Duplicates</a></h3>
<h3 id="transformation-of-data-using-function-or-mapping"><a class="header" href="#transformation-of-data-using-function-or-mapping">Transformation of Data using function or mapping</a></h3>
<h3 id="replacing-values"><a class="header" href="#replacing-values">Replacing values</a></h3>
<h3 id="handling-missing-data"><a class="header" href="#handling-missing-data">Handling Missing Data</a></h3>
<h3 id="analytics-types"><a class="header" href="#analytics-types">Analytics Types:</a></h3>
<ul>
<li>
<p><strong>Descriptive:</strong></p>
<ul>
<li>
<p>Descriptive analytics looks at what has happened in the past. As the
name suggests, the purpose of descriptive analytics is to simply
describe what has happened; it doesn’t try to explain why this might
have happened or to establish cause-and-effect relationships. The aim is
solely to provide an easily digestible snapshot.</p>
</li>
<li>
<p>Google Analytics is a good example of descriptive analytics in action;
it provides a simple overview of what’s been going on with your website,
showing you how many people visited in a given time period, for example,
or where your visitors came from. Similarly, tools like HubSpot will
show you how many people opened a particular email or engaged with a
certain campaign.</p>
</li>
<li>
<p>There are two main techniques used in descriptive analytics: Data
aggregation and data mining. Data aggregation is the process of
gathering data and presenting it in a summarized format. Let’s imagine
an ecommerce company collects all kinds of data relating to their
customers and people who visit their website. The aggregate data, or
summarized data, would provide an overview of this wider dataset—such as
the average customer age, for example, or the average number of
purchases made.</p>
</li>
</ul>
</li>
<li>
<p><strong>Predictive:</strong></p>
<ul>
<li>
<p>Predictive analytics seeks to predict what is likely to happen in the
future. Based on past patterns and trends, data analysts can devise
predictive models which estimate the likelihood of a future event or
outcome. This is especially useful as it enables businesses to plan
ahead.</p>
</li>
<li>
<p>Predictive models use the relationship between a set of variables to
make predictions; for example, you might use the correlation between
seasonality and sales figures to predict when sales are likely to drop.
If your predictive model tells you that sales are likely to go down in
summer, you might use this information to come up with a summer-related
promotional campaign, or to decrease expenditure elsewhere to make up
for the seasonal dip. Perhaps you own a restaurant and want to predict
how many takeaway orders you’re likely to get on a typical Saturday
night. Based on what your predictive model tells you, you might decide
to get an extra delivery driver on hand.</p>
</li>
<li>
<p>In addition to forecasting, predictive analytics is also used for
classification. A commonly used classification algorithm is logistic
regression, which is used to predict a binary outcome based on a set of
independent variables.</p>
</li>
</ul>
</li>
<li>
<p><strong>Prescriptive:</strong></p>
<ul>
<li>
<p>Prescriptive analytics looks at what has happened, why it happened, and
what might happen in order to determine what should be done next. In
other words, prescriptive analytics shows you how you can best take
advantage of the future outcomes that have been predicted. What steps
can you take to avoid a future problem? What can you do to capitalize on
an emerging trend?</p>
</li>
<li>
<p>Prescriptive analytics is, without doubt, the most complex type of
analysis, involving algorithms, machine learning, statistical methods,
and computational modeling procedures. Essentially, a prescriptive model
considers all the possible decision patterns or pathways a company might
take, and their likely outcomes. This enables you to see how each
combination of conditions and decisions might impact the future, and
allows you to measure the impact a certain decision might have. Based on
all the possible scenarios and potential outcomes, the company can
decide what is the best “route” or action to take.</p>
</li>
</ul>
</li>
</ul>
<h2 id="association-rules"><a class="header" href="#association-rules">Association Rules:</a></h2>
<p>Association rule learning is a rule-based machine learning method for
discovering interesting relations between variables in large databases. It is
intended to identify strong rules discovered in databases using some measures of
interestingness. In any given transaction with a variety of items, association
rules are meant to discover the rules that determine how or why certain items
are connected.</p>
<p>Association rule learning is a great system for predicting the behavior in data
interconnections. This makes it a noteworthy technique for classification, or
discovering patterns in data, when implementing machine learning methods.</p>
<ul>
<li>
<p><strong>Benefits:</strong> There are many benefits of using Association rules like
finding the pattern that helps understand the correlations and
co-occurrences between data sets. A very good real-world example that uses
Association rules would be medicine. Medicine uses Association rules to help
diagnose patients. When diagnosing patients there are many variables to
consider as many diseases will share similar symptoms. With the use of the
Association rules, doctors can determine the conditional probability of an
illness by comparing symptom relationships from past cases.</p>
</li>
<li>
<p><strong>Downfalls:</strong> However, Association rules also lead to many different
downfalls such as finding the appropriate parameter and threshold settings
for the mining algorithm. But there is also the downfall of having a large
number of discovered rules. The reason is that this does not guarantee
that the rules will be found relevant, but it could also cause the
algorithm to have low performance. Sometimes the implemented algorithms
will contain too many variables and parameters. For someone that doesn’t
have a good concept of data mining, this might cause them to have trouble
understanding it.</p>
</li>
</ul>
<h3 id="apriori-algorithm"><a class="header" href="#apriori-algorithm">Apriori Algorithm</a></h3>
<p>Apriori algorithm is given by R. Agrawal and R. Srikant in 1994 for finding
frequent itemsets in a dataset for boolean association rule. Name of the
algorithm is Apriori because it uses prior knowledge of frequent itemset
properties. We apply an iterative approach or level-wise search where k-frequent
itemsets are used to find k+1 itemsets.</p>
<p>To improve the efficiency of level-wise generation of frequent itemsets, an
important property is used called Apriori property which helps by reducing the
search space.</p>
<p><strong>Apriori Property:</strong> All non-empty subset of frequent itemset must be frequent.
The key concept of Apriori algorithm is its anti-monotonicity of support
measure. Apriori assumes that</p>
<blockquote>
<p>All subsets of a frequent itemset must be frequent(Apriori property). If an
itemset is infrequent, all its supersets will be infrequent.</p>
</blockquote>
<p><a href="https://www.geeksforgeeks.org/apriori-algorithm/">More Details</a></p>
<h3 id="fp-growthfrequent-pattern-growth-algorithm"><a class="header" href="#fp-growthfrequent-pattern-growth-algorithm">FP growth(Frequent Pattern Growth Algorithm)</a></h3>
<p>Frequent Pattern Growth Algorithm This algorithm is an improvement to the
Apriori method. A frequent pattern is generated without the need for candidate
generation. FP growth algorithm represents the database in the form of a tree
called a frequent pattern tree or FP tree.</p>
<p>This tree structure will maintain the association between the itemsets. The
database is fragmented using one frequent item. This fragmented part is called
“pattern fragment”. The itemsets of these fragmented patterns are analyzed. Thus
with this method, the search for frequent itemsets is reduced comparatively.</p>
<p><a href="https://www.geeksforgeeks.org/ml-frequent-pattern-growth-algorithm/">More
Details</a></p>
<h2 id="regression"><a class="header" href="#regression">Regression</a></h2>
<ul>
<li>
<p>Regression, one of the most common types of machine learning models,
estimates the relationships between variables. Whereas classification models
identify which category an observation belongs to, regression models
estimate a numeric value.</p>
</li>
<li>
<p>In the context of data science, regression specifically refers to the
estimation of a continuous dependent variable or response from a list of
input variables, or features.</p>
</li>
<li>
<p>Regression is essential for any machine learning problem that involves
continuous numbers, which includes a vast array of real-life applications:</p>
<ul>
<li>Financial forecasting, such as estimating housing or stock prices</li>
<li>Automobile testing</li>
<li>Weather analysis</li>
<li>Time series forecasting</li>
</ul>
</li>
</ul>
<h3 id="linear-regression"><a class="header" href="#linear-regression">Linear Regression</a></h3>
<p>Linear regression is one of the easiest and most popular Machine Learning
algorithms. It is a statistical method that is used for predictive analysis.
Linear regression makes predictions for continuous/real or numeric variables
such as sales, salary, age, product price, etc.</p>
<p>Linear regression algorithm shows a linear relationship between a dependent (y)
and one or more independent (y) variables, hence called as linear regression.
Since linear regression shows the linear relationship, which means it finds how
the value of the dependent variable is changing according to the value of the
independent variable.</p>
<p><a href="https://www.javatpoint.com/linear-regression-in-machine-learning">More Details</a></p>
<h3 id="logistic-regression"><a class="header" href="#logistic-regression">Logistic Regression</a></h3>
<p>Logistic regression is a process of modeling the probability of a discrete
outcome given an input variable. The most common logistic regression models a
binary outcome; something that can take two values such as true/false, yes/no,
and so on. Multinomial logistic regression can model scenarios where there are
more than two possible discrete outcomes. Logistic regression is a useful
analysis method for classification problems, where you are trying to determine
if a new sample fits best into a category. As aspects of cyber security are
classification problems, such as attack detection, logistic regression is a
useful analytic technique.</p>
<p><a href="https://www.geeksforgeeks.org/understanding-logistic-regression/">More Details</a></p>
<h2 id="classification"><a class="header" href="#classification">Classification</a></h2>
<p>Data Classification is the process of organizing data into categories for its
most effective and efficient use.</p>
<p>In a time where nearly everything is digitized, from personal records to highly
sensitive corporate data, it's about time we take a closer look into
classification. Data classification in data science refers to the process that
tags and categorizes any kind of data so that it can be better understood and
analyzed. The latter is what we'll be focusing on.</p>
<p>But also, a well-planned data classification system makes essential data easy to
find and retrieve. This can be of particular importance for risk management,
legal discovery, and compliance.</p>
<p><a href="https://levity.ai/blog/data-classification-types-applications">More Details</a></p>
<h3 id="naïve-bayes"><a class="header" href="#naïve-bayes">Naïve Bayes</a></h3>
<p>In statistics, naive Bayes classifiers are a family of simple &quot;probabilistic
classifiers&quot; based on applying Bayes' theorem with strong (naive) independence
assumptions between the features (see Bayes classifier). They are among the
simplest Bayesian network models, but coupled with kernel density estimation,
they can achieve high accuracy levels.</p>
<p>Naive Bayes classifiers are highly scalable, requiring a number of parameters
linear in the number of variables (features/predictors) in a learning problem.
Maximum-likelihood training can be done by evaluating a closed-form expression,
which takes linear time, rather than by expensive iterative approximation as
used for many other types of classifiers.</p>
<p><a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier">More Details</a></p>
<h3 id="decision-trees"><a class="header" href="#decision-trees">Decision Trees</a></h3>
<p>A decision tree is a type of supervised machine learning used to categorize or
make predictions based on how a previous set of questions were answered. The
model is a form of supervised learning, meaning that the model is trained and
tested on a set of data that contains the desired categorization.</p>
<p>The decision tree may not always provide a clear-cut answer or decision.
Instead, it may present options so the data scientist can make an informed
decision on their own. Decision trees imitate human thinking, so it’s generally
easy for data scientists to understand and interpret the results.</p>
<p><a href="https://www.mastersindatascience.org/learning/introduction-to-machine-learning-algorithms/decision-tree/#:%7E:text=A%20decision%20tree%20is%20a,that%20contains%20the%20desired%20categorization.">More
Details</a></p>
<h2 id="introduction-to-scikit-learn"><a class="header" href="#introduction-to-scikit-learn">Introduction to Scikit-learn</a></h2>
<p>Scikit-learn (Sklearn) is the most useful and robust library for machine
learning in Python. It provides a selection of efficient tools for machine
learning and statistical modeling including classification, regression,
clustering and dimensionality reduction via a consistence interface in Python.
This library, which is largely written in Python, is built upon NumPy, SciPy and
Matplotlib.</p>
<p><a href="https://en.wikipedia.org/wiki/Scikit-learn">More Details</a></p>
<h3 id="installations"><a class="header" href="#installations">Installations</a></h3>
<p>Install the 64bit version of Python 3, for instance from
<a href="https://www.python.org">https://www.python.org</a> Then run:</p>
<pre><code>pip install -U scikit-learn
</code></pre>
<p>In order to check your installation you can use</p>
<pre><code>python -m pip show scikit-learn  # to see which version and where
scikit-learn is installed python -m pip freeze  # to see all packages
installed in the active virtualenv python -c &quot;import sklearn;
sklearn.show_versions()&quot;
</code></pre>
<h3 id="dataset"><a class="header" href="#dataset">Dataset</a></h3>
<p><a href="https://scikit-learn.org/stable/datasets/toy_dataset.html">Read here</a></p>
<h3 id="matplotlib"><a class="header" href="#matplotlib">Matplotlib</a></h3>
<ul>
<li>Matplotlib is a comprehensive library for creating static, animated, and
interactive visualizations in Python. Matplotlib makes easy things easy and
hard things possible.
<ul>
<li>Create publication quality plots.</li>
<li>Make interactive figures that can zoom, pan, update.</li>
<li>Customize visual style and layout.</li>
<li>Export to many file formats .</li>
<li>Embed in JupyterLab and Graphical User Interfaces.</li>
<li>Use a rich array of third-party packages built on Matplotlib.</li>
</ul>
</li>
</ul>
<p><a href="https://matplotlib.org/stable/tutorials/introductory/usage.html">More Details</a></p>
<h3 id="filling-missing-values"><a class="header" href="#filling-missing-values">Filling missing values</a></h3>
<!-- TODO: filling missing values -->
<p><strong>NEEDS REFACTORING</strong></p>
<h3 id="regression-and-classification-using-scikit-learn"><a class="header" href="#regression-and-classification-using-scikit-learn">Regression and Classification using Scikit-learn</a></h3>
<ul>
<li>
<p>Python provides a lot of tools for implementing Classification and
Regression. The most popular open-source Python data science library is
scikit-learn. Let’s learn how to use scikit-learn to perform Classification
and Regression in simple terms.</p>
</li>
<li>
<p>The basic steps of supervised machine learning include:</p>
<ol>
<li>Load the necessary libraries</li>
<li>Load the dataset</li>
<li>Split the dataset into training and test set</li>
<li>Train the model</li>
<li>Evaluate the model</li>
</ol>
</li>
</ul>
<p><a href="https://www.educative.io/blog/scikit-learn-cheat-sheet-classification-regression-methods#implementation">More
Details</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="unit-v-big-data-analytics-and-model-evaluation"><a class="header" href="#unit-v-big-data-analytics-and-model-evaluation">Unit V: Big Data Analytics and Model Evaluation</a></h1>
<h2 id="clustering-algorithms"><a class="header" href="#clustering-algorithms">Clustering Algorithms</a></h2>
<ul>
<li>
<p>Clustering is an unsupervised machine learning task. You might also hear
this referred to as cluster analysis because of the way this method works.</p>
</li>
<li>
<p>Using a clustering algorithm means you're going to give the algorithm a lot
of input data with no labels and let it find any groupings in the data it
can.</p>
</li>
<li>
<p>Those groupings are called clusters. A cluster is a group of data points
that are similar to each other based on their relation to surrounding data
points. Clustering is used for things like feature engineering or pattern
discovery.</p>
</li>
<li>
<p>Types of clustering algorithms:</p>
<ul>
<li>
<p><strong>Distribution-based:</strong> With a distribution-based clustering approach,
all of the data points are considered parts of a cluster based on the
probability that they belong to a given cluster.</p>
</li>
<li>
<p><strong>Centroid-based:</strong> Centroid-based clustering is the one you probably
hear about the most. It's a little sensitive to the initial parameters
you give it, but it's fast and efficient.</p>
</li>
<li>
<p><strong>Hierarchical-based:</strong> Hierarchical-based clustering is typically used
on hierarchical data, like you would get from a company database or
taxonomies. It builds a tree of clusters so everything is organized from
the top-down.</p>
</li>
</ul>
</li>
</ul>
<h3 id="k-means"><a class="header" href="#k-means">K-Means</a></h3>
<ul>
<li>
<p>K-means clustering is the most commonly used clustering algorithm. It's a
centroid-based algorithm and the simplest unsupervised learning algorithm.</p>
</li>
<li>
<p>This algorithm tries to minimize the variance of data points within a
cluster. It's also how most people are introduced to unsupervised machine
learning.</p>
</li>
<li>
<p>K-means is best used on smaller data sets because it iterates over all of
the data points. That means it'll take more time to classify data points if
there are a large amount of them in the data set.</p>
</li>
<li>
<p>Since this is how k-means clusters data points, it doesn't scale well.</p>
</li>
<li>
<p>Implementation:</p>
</li>
</ul>
<!---->
<pre><code>from numpy import unique
from numpy import where
from matplotlib import pyplot
from sklearn.datasets import make_classification
from sklearn.cluster import KMeans

# initialize the data set we'll work with
training_data, _ = make_classification(
    n_samples=1000,
    n_features=2,
    n_informative=2,
    n_redundant=0,
    n_clusters_per_class=1,
    random_state=4
)

# define the model
kmeans_model = KMeans(n_clusters=2)

# assign each data point to a cluster
dbscan_result = dbscan_model.fit_predict(training_data)

# get all of the unique clusters
dbscan_clusters = unique(dbscan_result)

# plot the DBSCAN clusters
for dbscan_cluster in dbscan_clusters:
    # get data points that fall in this cluster
    index = where(dbscan_result == dbscan_clusters)
    # make the plot
    pyplot.scatter(training_data[index, 0], training_data[index, 1])

# show the DBSCAN plot
pyplot.show()
</code></pre>
<h3 id="hierarchical-clustering"><a class="header" href="#hierarchical-clustering">Hierarchical Clustering</a></h3>
<p>Hierarchical clustering, also known as hierarchical cluster analysis, is an
algorithm that groups similar objects into groups called clusters. The endpoint
is a set of clusters, where each cluster is distinct from each other cluster,
and the objects within each cluster are broadly similar to each other.</p>
<p><a href="https://www.displayr.com/what-is-hierarchical-clustering/">More Details</a></p>
<h3 id="time-series-analysis"><a class="header" href="#time-series-analysis">Time-series analysis</a></h3>
<p>Time series analysis is a specific way of analyzing a sequence of data points
collected over an interval of time. In time series analysis, analysts record
data points at consistent intervals over a set period of time rather than just
recording the data points intermittently or randomly. However, this type of
analysis is not merely the act of collecting data over time.</p>
<p>What sets time series data apart from other data is that the analysis can show
how variables change over time. In other words, time is a crucial variable
because it shows how the data adjusts over the course of the data points as well
as the final results. It provides an additional source of information and a set
order of dependencies between the data.</p>
<p><a href="https://www.tableau.com/learn/articles/time-series-analysis">More Details</a></p>
<h2 id="introduction-to-text-analysis"><a class="header" href="#introduction-to-text-analysis">Introduction to Text Analysis</a></h2>
<p>Text analysis (TA) is a machine learning technique used to automatically extract
valuable insights from unstructured text data. Companies use text analysis tools
to quickly digest online data and documents, and transform them into actionable
insights.</p>
<p>You can us text analysis to extract specific information, like keywords, names,
or company information from thousands of emails, or categorize survey responses
by sentiment and topic.</p>
<p><a href="https://monkeylearn.com/text-analysis/">More Details</a></p>
<h3 id="text-preprocessing"><a class="header" href="#text-preprocessing">Text-preprocessing</a></h3>
<p>Text preprocessing is an approach for cleaning and preparing text data for use
in a specific context. Developers use it in almost all natural language
processing (NLP) pipelines, including voice recognition software, search engine
lookup, and machine learning model training. It is an essential step because
text data can vary. From its format (website, text message, voice recognition)
to the people who create the text (language, dialect), there are plenty of
things that can introduce noise into your data.</p>
<p>The ultimate goal of cleaning and preparing text data is to reduce the text to
only the words that you need for your NLP goals.</p>
<p><a href="https://www.codecademy.com/learn/text-preprocessing/modules/nlp-text-preprocessing">More
Details</a></p>
<h3 id="bag-of-words"><a class="header" href="#bag-of-words">Bag of words</a></h3>
<ul>
<li>
<p>The bag-of-words model is a way of representing text data when modeling text
with machine learning algorithms.</p>
</li>
<li>
<p>The bag-of-words model is simple to understand and implement and has seen
great success in problems such as language modeling and document
classification.</p>
</li>
<li>
<p>A bag-of-words model, or BoW for short, is a way of extracting features from
text for use in modeling, such as with machine learning algorithms.</p>
</li>
<li>
<p>The approach is very simple and flexible, and can be used in a myriad of
ways for extracting features from documents.</p>
</li>
<li>
<p>A bag-of-words is a representation of text that describes the occurrence of
words within a document. It involves two things:</p>
<ol>
<li>A vocabulary of known words.</li>
<li>A measure of the presence of known words.</li>
</ol>
</li>
<li>
<p>It is called a “bag” of words, because any information about the order or
structure of words in the document is discarded. The model is only concerned
with whether known words occur in the document, not where in the document.</p>
</li>
<li>
<p><a href="https://machinelearningmastery.com/gentle-introduction-bag-words-model/">More
Details</a></p>
</li>
</ul>
<h3 id="tf-idf-and-topics"><a class="header" href="#tf-idf-and-topics">TF-IDF and topics</a></h3>
<ul>
<li>
<p>TF-IDF stands for term frequency-inverse document frequency and it is a
measure, used in the fields of information retrieval (IR) and machine
learning, that can quantify the importance or relevance of string
representations (words, phrases, lemmas, etc)  in a document amongst a
collection of documents (also known as a corpus).</p>
</li>
<li>
<p>TF-IDF can be broken down into two parts TF (term frequency) and IDF
(inverse document frequency).</p>
</li>
<li>
<p>Term frequency works by looking at the frequency of a particular term you
are concerned with relative to the document. There are multiple measures, or
ways, of defining frequency:</p>
<ul>
<li>Number of times the word appears in a document (raw count).</li>
<li>Term frequency adjusted for the length of the document (raw count of
occurences divided by number of words in the document).</li>
<li>Logarithmically scaled frequency (e.g. log(1 + raw count)).</li>
<li>Boolean frequency (e.g. 1 if the term occurs, or 0 if the term does not
occur, in the document).</li>
</ul>
</li>
</ul>
<h3 id="need-and-introduction-to-social-network-analysis"><a class="header" href="#need-and-introduction-to-social-network-analysis">Need and Introduction to social network analysis</a></h3>
<ul>
<li>
<p>Social network analysis (SNA) is the process of investigating social
structures through the use of networks and graph theory.[1] It
characterizes networked structures in terms of nodes (individual actors,
people, or things within the network) and the ties, edges, or links
(relationships or interactions) that connect them.</p>
</li>
<li>
<p>Need for social network analysis:</p>
<ul>
<li>
<p>Social network analysis (SNA) can provide insight into social influences
within teams, and identify cultural issues.</p>
</li>
<li>
<p>The research conducted for SNA is interested in individuals, but the
analysis itself focuses on connectivity: how individuals collaborate.</p>
</li>
<li>
<p>SNA has been used as a strategic approach to team building, and to
understand how team building can change the dynamics of an
organisation’s social network.</p>
</li>
</ul>
</li>
<li>
<p><a href="https://en.wikipedia.org/wiki/Social_network_analysis">More Details</a></p>
</li>
</ul>
<h3 id="introduction-to-business-analysis"><a class="header" href="#introduction-to-business-analysis">Introduction to business analysis.</a></h3>
<p>Business analysis is a professional discipline of identifying business needs and
determining solutions to business problems. Solutions often include a
software-systems development component, but may also consist of process
improvements, organizational change or strategic planning and policy
development.</p>
<h2 id="model-evaluation-and-selection"><a class="header" href="#model-evaluation-and-selection">Model Evaluation and Selection</a></h2>
<p>Model evaluation is a method of assessing the correctness of models on test
data. The test data consists of data points that have not been seen by the model
before.</p>
<p>Model selection is a technique for selecting the best model after the individual
models are evaluated based on the required criteria.</p>
<p><a href="https://neptune.ai/blog/the-ultimate-guide-to-evaluation-and-selection-of-models-in-machine-learning">More
Details</a></p>
<h3 id="metrics-for-evaluating-classifier-performance"><a class="header" href="#metrics-for-evaluating-classifier-performance">Metrics for Evaluating Classifier Performance</a></h3>
<p>Evaluation metrics are tied to machine learning tasks. There are different
metrics for the tasks of classification and regression. Some metrics, like
precision-recall, are useful for multiple tasks. Classification and regression
are examples of supervised learning, which constitutes a majority of machine
learning applications. Using different metrics for performance evaluation, we
should be able to improve our model’s overall predictive power before we roll it
out for production on unseen data. Without doing a proper evaluation of the
Machine Learning model by using different evaluation metrics, and only depending
on accuracy, can lead to a problem when the respective model is deployed on
unseen data and may end in poor predictions.</p>
<p><a href="https://www.analyticsvidhya.com/blog/2021/07/metrics-to-evaluate-your-classification-model-to-take-the-right-decisions/">More
Details</a></p>
<h3 id="holdout-method-and-random-sub-sampling"><a class="header" href="#holdout-method-and-random-sub-sampling">Holdout Method and Random Sub sampling</a></h3>
<p>Hold-Out Method is a resampling technique with a basic idea of dividing the
training dataset into two parts i.e. train and test. On one part(train) you try
to train the model and on the second part(test) i.e. the data which is unseen
for the model, you make the prediction and check how well your model works on
it.</p>
<p>Random subsampling performs K data splits of the entire sample. For each data
split, a fixed number of observations is chosen without replacement from the
sample and kept aside as the test data.</p>
<p><a href="https://blog.ineuron.ai/Hold-Out-Method-Random-Sub-Sampling-Method-3MLDEXAZML">More
Details</a></p>
<h3 id="parameter-tuning-and-optimization"><a class="header" href="#parameter-tuning-and-optimization">Parameter Tuning and Optimization</a></h3>
<p>In machine learning, hyperparameter optimization or tuning is the problem of
choosing a set of optimal hyperparameters for a learning algorithm. A
hyperparameter is a parameter whose value is used to control the learning
process. By contrast, the values of other parameters (typically node weights)
are learned.</p>
<p><a href="https://en.wikipedia.org/wiki/Hyperparameter_optimization">More Details</a></p>
<h3 id="result-interpretation"><a class="header" href="#result-interpretation">Result Interpretation</a></h3>
<p>Data interpretation refers to the process of using diverse analytical methods to
review data and arrive at relevant conclusions. The interpretation of data helps
researchers to categorize, manipulate, and summarize the information in order to
answer critical questions.</p>
<p><a href="https://www.datapine.com/blog/data-interpretation-methods-benefits-problems/">More
Details</a></p>
<h3 id="clustering-and-time-series-analysis-using-scikit--learn"><a class="header" href="#clustering-and-time-series-analysis-using-scikit--learn">Clustering and Time-series analysis using Scikit- learn</a></h3>
<p>Clustering methods, one of the most useful unsupervised ML methods, used to find
similarity &amp; relationship patterns among data samples. After that, they cluster
those samples into groups having similarity based on features. Clustering
determines the intrinsic grouping among the present unlabeled data, that’s why
it is important.</p>
<p>The Scikit-learn library have sklearn.cluster to perform clustering of unlabeled
data. Under this module scikit-leran have the following clustering methods −</p>
<p><a href="https://www.tutorialspoint.com/scikit_learn/scikit_learn_clustering_methods.htm">More
Details</a></p>
<h3 id="sklearnmetrics"><a class="header" href="#sklearnmetrics">sklearn.metrics</a></h3>
<ul>
<li>
<p>The sklearn.metrics module implements functions assessing prediction error
for specific purposes. These metrics are detailed in sections on
Classification metrics, Multilabel ranking metrics, Regression metrics and
Clustering metrics.</p>
</li>
<li>
<p>Finally, Dummy estimators are useful to get a baseline value of those
metrics for random predictions.</p>
</li>
<li>
<p>For the most common use cases, you can designate a scorer object with the
scoring parameter. All scorer objects follow the convention that higher
return values are better than lower return values. Thus metrics which
measure the distance between the model and the data, like
metrics.mean_squared_error, are available as neg_mean_squared_error
which return the negated value of the metric.</p>
</li>
<li>
<p>The module sklearn.metrics also exposes a set of simple functions measuring
a prediction error given ground truth and prediction:</p>
<ul>
<li>
<p>functions ending with _score return a value to maximize, the higher the
better.</p>
</li>
<li>
<p>functions ending with _error or _loss return a value to minimize, the
lower the better. When converting into a scorer object using
make_scorer, set the greater_is_better parameter to False (True by
default; see the parameter description below).</p>
</li>
</ul>
</li>
<li>
<p><a href="https://scikit-learn.org/stable/modules/model_evaluation.html">More
Details</a></p>
</li>
</ul>
<h3 id="confusion-matrix"><a class="header" href="#confusion-matrix">Confusion matrix</a></h3>
<ul>
<li>
<p>A confusion matrix is a table that is often used to describe the performance
of a classification model (or &quot;classifier&quot;) on a set of test data for which
the true values are known. The confusion matrix itself is relatively simple
to understand, but the related terminology can be confusing.</p>
</li>
<li>
<p>I wanted to create a &quot;quick reference guide&quot; for confusion matrix
terminology because I couldn't find an existing resource that suited my
requirements: compact in presentation, using numbers instead of arbitrary
variables, and explained both in terms of formulas and sentences.</p>
</li>
<li>
<p><a href="https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/">More
Details</a></p>
</li>
</ul>
<h3 id="auc-roc-curves"><a class="header" href="#auc-roc-curves">AUC-ROC Curves</a></h3>
<p>AUC-ROC is the valued metric used for evaluating the performance in
classification models. The AUC-ROC metric clearly helps determine and tell us
about the capability of a model in distinguishing the classes. The judging
criteria being - Higher the AUC, better the model. AUC-ROC curves are frequently
used to depict in a graphical way the connection and trade-off between
sensitivity and specificity for every possible cut-off for a test being
performed or a combination of tests being performed. The area under the ROC
curve gives an idea about the benefit of using the test for the underlying
question. AUC - ROC curves are also a performance measurement for the
classification problems at various threshold settings.</p>
<p><a href="https://analyticsindiamag.com/understanding-the-auc-roc-curve-in-machine-learning-classification/">More
Details</a></p>
<h3 id="elbow-plot"><a class="header" href="#elbow-plot">Elbow plot</a></h3>
<p>In cluster analysis, the elbow method is a heuristic used in determining the
number of clusters in a data set. The method consists of plotting the explained
variation as a function of the number of clusters, and picking the elbow of the
curve as the number of clusters to use. The same method can be used to choose
the number of parameters in other data-driven models, such as the number of
principal components to describe a data set.</p>
<p><a href="https://en.wikipedia.org/wiki/Elbow_method_(clustering)">More Details</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="unit-vi-data-visualization-and-hadoop"><a class="header" href="#unit-vi-data-visualization-and-hadoop">Unit VI: Data Visualization and Hadoop</a></h1>
<h2 id="introduction-to-data-visualization"><a class="header" href="#introduction-to-data-visualization">Introduction to Data Visualization</a></h2>
<p>Data visualization is actually a set of data points and information that are
represented graphically to make it easy and quick for user to understand. Data
visualization is good if it has a clear meaning, purpose, and is very easy to
interpret, without requiring context. Tools of data visualization provide an
accessible way to see and understand trends, outliers, and patterns in data by
using visual effects or elements such as a chart, graphs, and maps.</p>
<p><a href="https://www.geeksforgeeks.org/short-note-on-data-visualization/">More Details</a></p>
<h2 id="challenges-to-big-data-visualization"><a class="header" href="#challenges-to-big-data-visualization">Challenges to Big data visualization</a></h2>
<ul>
<li>
<p>Scalability and dynamics are two major challenges in visual analytics.</p>
</li>
<li>
<p>Big Data visualization can be an extremely powerful business capability, but
before an organization can take advantage of it some key issues need to be
addressed. These include:</p>
<ul>
<li>
<p><strong>Availability of visualization specialists:</strong> Many Big Data
visualization tools are designed to be easy enough for anyone in an
organization to use, often suggesting appropriate Big Data visualization
examples  for the data sets under analysis. But to get the most out of
some tools  it may be necessary to employ a specialist in big data
visualization techniques who can select the best data sets and
visualization styles to ensure the data is exploited to the maximum.</p>
</li>
<li>
<p><strong>Visualization hardware resources:</strong> Under the hood, Big Data
visualization is essentially a computing task, and the ability to carry
out this task quickly – to enable organizations to make decisions in a
timely manner using real-time data – may require powerful computer
hardware, fast storage systems, or even a move to cloud. That means Big
Data visualization initiatives are as much an IT project as a management
project.</p>
</li>
<li>
<p><strong>Data quality:</strong> The insights that can be drawn from Big Data
visualization are only as accurate as the data that is being visualized:
if it is inaccurate or out of date then the value of any insights is
questionable. That means people and processes need to be put in place
to manage corporate data, metadata, data sources, and any
transformations or data cleaning that are performed before storage.</p>
</li>
</ul>
</li>
</ul>
<h2 id="types-of-data-visualization"><a class="header" href="#types-of-data-visualization">Types of data visualization</a></h2>
<ul>
<li>
<p>Some of the most common types of data visualization chart and graph formats
include:</p>
<ul>
<li>Column Chart</li>
<li>Bar Graph</li>
<li>Line Graph</li>
<li>Heat Map</li>
<li>Pie Chart</li>
<li>Scatter Plot Chart</li>
<li>Bubble Chart</li>
<li>Area Chart</li>
<li>Stacked Bar Graph</li>
<li>Stacked Column Chart</li>
<li>Dual Axis Chart</li>
<li>Mekko Chart</li>
<li>Waterfall Chart</li>
<li>Bullet Graph</li>
<li>Funnel Chart</li>
</ul>
</li>
<li>
<p>Also read the section below for data visualization techniques in detail.</p>
</li>
</ul>
<h2 id="data-visualization-techniques"><a class="header" href="#data-visualization-techniques">Data Visualization Techniques</a></h2>
<p><a href="https://online.hbs.edu/blog/post/data-visualization-techniques">More details and visual representations of
graphs</a></p>
<h2 id="visualizing-big-data"><a class="header" href="#visualizing-big-data">Visualizing Big Data</a></h2>
<ul>
<li>Big data visualization refers to the implementation of more contemporary
visualization techniques to illustrate the relationships within data.
Visualization tactics include applications that can display real-time
changes and more illustrative graphics, thus going beyond pie, bar and other
charts.</li>
</ul>
<h2 id="tools-used-in-data-visualization"><a class="header" href="#tools-used-in-data-visualization">Tools used in Data Visualization</a></h2>
<ul>
<li>
<p>Data visualization tools are software applications that render information
in a visual format such as a graph, chart, or heat map for data analysis
purposes. Such tools make it easier to understand and work with massive
amounts of data. With effective data visualization tools, people can make
data-driven decisions without having to spend valuable time trying to
wrangle raw data into an interpretable format. Properly configured, data
visualization software does that work for you, sifting through vast stores
of information to present only the most meaningful, relevant data.</p>
</li>
<li>
<p>Some commonly used tools are:</p>
<ul>
<li>
<p>Zoho Analytics: Focusing on ease of use – a particularly key attribute
as data tools grow – Zoho analytics is a self service option. Meaning
that users will not need the assistance of IT staff or professional data
scientists to glean insight from data.</p>
</li>
<li>
<p>IBM Cognos Analytics: Driven by their commitment to Big Data, IBM’s
analytics package offers a variety of self service options to more
easily identify insight.</p>
</li>
<li>
<p>QlikSense and QlikView: The Qlik solution touts its ability to perform
the more complex analysis that finds hidden insights.</p>
</li>
<li>
<p>Microsoft PowerBI: The Power BI tools enables you to connect with
hundreds of data sources, then publish reports on the Web and across
mobile devices.</p>
</li>
<li>
<p>Oracle Visual Analyzer: A web-based tool, Visual Analyzer allows
creation of curated dashboards to help discover correlations and
patterns in data.</p>
</li>
<li>
<p>SAP Lumira: Calling it “self service data visualization for everyone,”
Lumira allows you to combine your visualizations into storyboards.</p>
</li>
<li>
<p>SAS Visual Analytics: The SAS solution promotes its “scalability and
governance,” along with dynamic visuals and flexible deployment options.</p>
</li>
<li>
<p>Tableau Desktop: Tableau’s interactive dashboards allow you to “uncover
hidden insights on the fly,” and power users can manage metadata to make
the most of disparate data sources.</p>
</li>
<li>
<p>TIBCO Spotfire: Offers analytics software as a service, and touts itself
as a solution that “scales from a small team to the entire
organization.”</p>
</li>
</ul>
</li>
<li>
<p><a href="https://www.simplilearn.com/data-visualization-tools-article">More details and visual representations of
graphs</a></p>
</li>
</ul>
<h2 id="hadoop-ecosystem"><a class="header" href="#hadoop-ecosystem">Hadoop ecosystem</a></h2>
<ul>
<li>Hadoop Ecosystem is a platform or a suite which provides various services to
solve the big data problems. It includes Apache projects and various
commercial tools and solutions. There are four major elements of Hadoop i.e.
HDFS, MapReduce, YARN, and Hadoop Common. Most of the tools or solutions are
used to supplement or support these major elements. All these tools work
collectively to provide services such as absorption, analysis, storage and
maintenance of data etc.</li>
</ul>
<p><img src="pictures/hadoop_eco.png" alt="Hadoop Ecosystem" /></p>
<ul>
<li>
<p>Following are the components that collectively form a Hadoop ecosystem:</p>
<ul>
<li><strong>HDFS:</strong> Hadoop Distributed File System</li>
<li><strong>YARN:</strong> Yet Another Resource Negotiator</li>
<li><strong>MapReduce:</strong> Programming based Data Processing</li>
<li><strong>Spark:</strong> In-Memory data processing</li>
<li><strong>PIG, HIVE:</strong> Query based processing of data services</li>
<li><strong>HBase:</strong> NoSQL Database</li>
<li><strong>Mahout, Spark MLLib:</strong> Machine Learning algorithm libraries</li>
<li><strong>Solar, Lucene:</strong> Searching and Indexing</li>
<li><strong>Zookeeper:</strong> Managing cluster</li>
<li><strong>Oozie:</strong> Job Scheduling</li>
</ul>
</li>
<li>
<p><a href="https://www.geeksforgeeks.org/hadoop-ecosystem/">More Details</a></p>
</li>
</ul>
<h3 id="map-reduce"><a class="header" href="#map-reduce">Map Reduce</a></h3>
<ul>
<li>
<p>By making the use of distributed and parallel algorithms, MapReduce makes it
possible to carry over the processing’s logic and helps to write
applications which transform big data sets into a manageable one.</p>
</li>
<li>
<p>MapReduce makes the use of two functions i.e. Map() and Reduce() whose task
is:</p>
<ol>
<li>Map() performs sorting and filtering of data and thereby organizing them
in the form of group. Map generates a key-value pair based result which is
later on processed by the Reduce() method.</li>
<li>Reduce(), as the name suggests does the summarization by aggregating the
mapped data. In simple, Reduce() takes the output generated by Map() as
input and combines those tuples into smaller set of tuples.</li>
</ol>
</li>
</ul>
<h3 id="pig"><a class="header" href="#pig">Pig</a></h3>
<ul>
<li>Pig was basically developed by Yahoo which works on a pig Latin language,
which is Query based language similar to SQL.</li>
<li>It is a platform for structuring the data flow, processing and analyzing
huge data sets.</li>
<li>Pig does the work of executing commands and in the background, all the
activities of MapReduce are taken care of. After the processing, pig stores
the result in HDFS.</li>
<li>Pig Latin language is specially designed for this framework which runs on
Pig Runtime. Just the way Java runs on the JVM.</li>
<li>Pig helps to achieve ease of programming and optimization and hence is a
major segment of the Hadoop Ecosystem.</li>
</ul>
<h3 id="hive"><a class="header" href="#hive">Hive</a></h3>
<ul>
<li>With the help of SQL methodology and interface, HIVE performs reading and
writing of large data sets. However, its query language is called as HQL
(Hive Query Language).</li>
<li>It is highly scalable as it allows real-time processing and batch processing
both. Also, all the SQL datatypes are supported by Hive thus, making the
query processing easier.</li>
<li>Similar to the Query Processing frameworks, HIVE too comes with two
components: JDBC Drivers and HIVE Command Line.</li>
<li>JDBC, along with ODBC drivers work on establishing the data storage
permissions and connection whereas HIVE Command line helps in the processing
of queries.</li>
</ul>
<h2 id="analytical-techniques-used-in-big-data-visualization"><a class="header" href="#analytical-techniques-used-in-big-data-visualization">Analytical techniques used in Big data visualization</a></h2>
<p><a href="u3.4.html#types-of-data-visualization">Refer Data Visualization Techniques Section
above</a></p>
<h2 id="data-visualization-using-python"><a class="header" href="#data-visualization-using-python">Data Visualization using Python</a></h2>
<h3 id="line-plot"><a class="header" href="#line-plot">Line plot</a></h3>
<p>Matplotlib is a data visualization library in Python. The pyplot, a sublibrary
of matplotlib, is a collection of functions that helps in creating a variety of
charts.  Line charts are used to represent the relation between two data X and Y
on a different axis. Here we will see some of the examples of a line chart in
Python :</p>
<p><a href="https://www.geeksforgeeks.org/line-chart-in-matplotlib-python/">More Details</a></p>
<h3 id="scatter-plot"><a class="header" href="#scatter-plot">Scatter plot</a></h3>
<p><a href="https://www.w3schools.com/python/python_ml_scatterplot.asp">Read here</a></p>
<h3 id="histogram"><a class="header" href="#histogram">Histogram</a></h3>
<p>A histogram is basically used to represent data provided in a form of some
groups.It is accurate method for the graphical representation of numerical data
distribution.It is a type of bar plot where X-axis represents the bin ranges
while Y-axis gives information about frequency.</p>
<p><a href="https://www.geeksforgeeks.org/plotting-histogram-in-python-using-matplotlib/">More
Details</a></p>
<h3 id="density-plot"><a class="header" href="#density-plot">Density plot</a></h3>
<p>Density Plot is a type of data visualization tool. It is a variation of the
histogram that uses ‘kernel smoothing’ while plotting the values. It is a
continuous and smooth version of a histogram inferred from a data.</p>
<p>Density plots uses Kernel Density Estimation (so they are also known as Kernel
density estimation plots or KDE) which is a probability density function. The
region of plot with a higher peak is the region with maximum data points
residing between those values.</p>
<p>Density plots can be made using pandas, seaborn, etc. In this article, we will
generate density plots using Pandas. We will be using two datasets of the
Seaborn Library namely – ‘car_crashes’ and ‘tips’.</p>
<p><a href="https://www.geeksforgeeks.org/density-plots-with-pandas-in-python/">More
Details</a></p>
<h3 id="box-plot"><a class="header" href="#box-plot">Box-plot</a></h3>
<p>A Box Plot is also known as Whisker plot is created to display the summary of
the set of data values having properties like minimum, first quartile, median,
third quartile and maximum. In the box plot, a box is created from the first
quartile to the third quartile, a vertical line is also there which goes through
the box at the median. Here x-axis denotes the data to be plotted while the
y-axis shows the frequency distribution.</p>
<p><a href="https://www.geeksforgeeks.org/box-plot-in-python-using-matplotlib/">More
Details</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="questions-2"><a class="header" href="#questions-2">Questions</a></h1>
<p><strong>Questions from SKN's recent(May 2022) prelim examinations</strong></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="web-technologies-1"><a class="header" href="#web-technologies-1">Web technologies</a></h1>
<ul>
<li>
<p>Unit III <strong>Java Servlets and XML</strong></p>
<p>Servlet: Servlet architecture overview, A “Hello World” servlet, Servlets generating dynamic
content, Servlet life cycle, parameter data, sessions, cookies, URL rewriting, other Servlet
capabilities, data storage, Servlets concurrency, databases (MySQL) and Java Servlets. XML:
XML documents and vocabularies, XML declaration, XML Namespaces, DOM based XML
processing, transforming XML documents, DTD: Schema, elements, attributes. AJAX:
Introduction, Working of AJAX.</p>
</li>
<li>
<p>Unit IV <strong>JSP and Web Services</strong></p>
<p>JSP: Introduction to Java Server Pages, JSP and Servlets, running JSP applications, Basic JSP,
JavaBeans classes and JSP, Support for the Model-View-Controller paradigm, JSP related
technologies. Web Services: Web Service concepts, Writing a Java Web Service, Writing a Java
web service client, Describing Web Services: WSDL, Communicating Object data: SOAP.
Struts: Overview, architecture, configuration, actions, interceptors, result types, validations,
localization, exception handling, annotations.</p>
</li>
<li>
<p>Unit V <strong>Server Side Scripting Languages</strong></p>
<p>PHP: Introduction to PHP, uses of PHP, general syntactic characteristics, Primitives, operations
and expressions, output, control statements, arrays, functions, pattern matching, form handling,
files, cookies, session tracking, using MySQL with PHP, WAP and WML. Introduction to
ASP.NET: Overview of the .NET Framework, Overview of C#, Introduction to ASP.NET,
ASP.NET Controls, Web Services. Overview of Node JS.</p>
</li>
<li>
<p>Unit VI <strong>Ruby and Rails</strong></p>
<p>Introduction to Ruby: Origins &amp; uses of Ruby, scalar types and their operations, simple input
and output, control statements, fundamentals of arrays, hashes, methods, classes, code blocks and
iterators, pattern matching. Introduction to Rails: Overview of Rails, Document Requests,
Processing Forms, Rails Applications and Databases, Layouts, Rails with Ajax. Introduction to
EJB.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="java-servlets-and-xml"><a class="header" href="#java-servlets-and-xml">Java Servlets and XML</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="jsp-and-web-services"><a class="header" href="#jsp-and-web-services">JSP and Web Services</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="server-side-scripting-languages"><a class="header" href="#server-side-scripting-languages">Server Side Scripting Languages</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ruby-and-rails"><a class="header" href="#ruby-and-rails">Ruby and Rails</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="questions-3"><a class="header" href="#questions-3">Questions</a></h1>
<p><strong>Questions from SKN's recent(May 2022) prelim examinations</strong></p>
<p><strong>1. Write benefits of using PHP and mysql. Explain PHP module to insert a
record in MySQL database.</strong></p>
<ul>
<li>
<p>Major Advantages of PHP and MySQL Development:</p>
<ul>
<li>
<p>Cost-effective personalized PHP applications solutions;</p>
</li>
<li>
<p>A complete open-source platform;</p>
</li>
<li>
<p>Frequently updated (these updates are also available for free);</p>
</li>
<li>
<p>Availability of various add-ons and plugins;</p>
</li>
<li>
<p>Superior website performance;</p>
</li>
<li>
<p>Vast amount of database interfaces;</p>
</li>
<li>
<p>PHP checks various levels of security;</p>
</li>
<li>
<p>Integration facility with various other open-source platforms;</p>
</li>
<li>
<p>Integrates other software languages such as C, C++, JAVA/AJAX, etc;</p>
</li>
<li>
<p>Supports Joomla, Drupal and WordPress CMS, and osCommerce and Zen Cart
shopping carts;</p>
</li>
<li>
<p>HTML Code can be embedded within PHP Code;</p>
</li>
<li>
<p>Cross-platform ability;</p>
</li>
<li>
<p>Server-side web programming language;</p>
</li>
<li>
<p>Large user community.</p>
</li>
<li>
<p>PHP uses <strong>mysqli_query</strong> function to insert records in table. This
function takes three parameters and returns TRUE on success or FALSE on
failure.</p>
</li>
<li>
<p>The mysqli_query() function accepts a string value representing a query
as one of the parameters and, executes/performs the given query on the
database.</p>
</li>
<li>
<p>Syntax:</p>
</li>
</ul>
<!---->
<pre><code>mysqli_query($con, query)
</code></pre>
</li>
</ul>
<p><strong>2. What is the use of the XmlHttpRequest object? Explain its use with the help
of simple javascript code.</strong></p>
<ul>
<li>
<p>XMLHttpRequest (XHR) objects are used to interact with servers. You can
retrieve data from a URL without having to do a full page refresh. This
enables a Web page to update just part of a page without disrupting what the
user is doing. XMLHttpRequest is used heavily in AJAX programming.</p>
</li>
<li>
<p>XMLHttpRequest Example: When you type a character in the input field below,
an XMLHttpRequest is sent to the server, and some name suggestions are
returned (from the server):</p>
<p><img src="pictures/xhr_example.png" alt="xhr example" /></p>
</li>
<li>
<p>Code:</p>
<pre><code class="language-js">    // Create an xhr object
  var xhttp = new XMLHttpRequest();
    // specify the function to execute when xhr object's status changes
  xhttp.onreadystatechange = function() {
    // When readyState is 4 and status is 200 then response is ready
      if (this.readyState == 4 &amp;&amp; this.status == 200) {
    // The responseText property returns the server response as a text string
         document.getElementById(&quot;demo&quot;).innerHTML = xhttp.responseText;
      }
  };
  xhttp.open(&quot;GET&quot;, &quot;filename&quot;, true);
  xhttp.send();
</code></pre>
</li>
</ul>
<!-- CODE -->
<p><strong>3. Draw and explain how AJAX works with the help of suitable examples.</strong></p>
<ul>
<li>
<p>AJAX = Asynchronous JavaScript and XML.</p>
</li>
<li>
<p>AJAX is a technique for creating fast and dynamic web pages.</p>
</li>
<li>
<p>AJAX allows web pages to be updated asynchronously by exchanging small
amounts of data with the server behind the scenes. This means that it is
possible to update parts of a web page, without reloading the whole page.</p>
</li>
<li>
<p>How AJAX works:</p>
<p><img src="pictures/ajax_working.gif" alt="ajax working" /></p>
</li>
<li>
<p>Example:</p>
<ul>
<li>AJAX was made popular in 2005 by Google, with Google Suggest.</li>
<li>Google Suggest is using AJAX to create a very dynamic web interface: When you start typing in Google's search box, a JavaScript sends the letters off to a server and the server returns a list of suggestions.</li>
</ul>
</li>
</ul>
<p><strong>4. Write a program of your choice that demonstrates use of properties of DOM.
Also list the limitations of using XML.</strong></p>
<p><strong>5. How to use interceptors in strut 2? List and describe important
interceptors provided by strut 2 framework.</strong></p>
<p><strong>6. What are the web services? List and explain types and components of web
services.</strong></p>
<p><strong>7. What different configuration files are required to develop any struts
application?</strong></p>
<p><strong>8. What are enterprise java beans? Draw and explain main components of EJB
architecture.</strong></p>
<p><strong>9. Explain what is Angular Expression? Explain what is the key difference
between angular expressions and JavaScript expressions?</strong></p>
<p><strong>10. Write a PHP script to display the squares and Cubes of 1 to 10 numbers.</strong></p>
<p><strong>11. What is an association array in PHP? Explain it with the help of simple
PHP code.</strong></p>
<p><strong>12. Explain various directives in AngularJS &amp; Create simple angular JS
application to display, &quot;Hello, Input Name&quot; using proper directive.</strong></p>
<p><strong>13. What is EJB? Explain types of EJB? Also explain uses of Ruby.</strong></p>
<p><strong>14. Draw and explain the role of EJB container in enterprise application.</strong></p>
<p><strong>15. Explain how Rails implements AJAX? Mention what are the positive aspects
of Rails.</strong></p>
<p><strong>16. Explain how you define instance variable, global variable and class
variable in Ruby? Explain what is rake in Rails.</strong></p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
            </nav>

        </div>

        <!-- Livereload script (if served using the cli tool) -->
        <script type="text/javascript">
            const wsProtocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsAddress = wsProtocol + "//" + location.host + "/" + "__livereload";
            const socket = new WebSocket(wsAddress);
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
    </body>
</html>
